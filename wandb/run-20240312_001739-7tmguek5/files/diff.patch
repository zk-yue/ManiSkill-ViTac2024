diff --git a/configs/parameters/long_open_lock.yaml b/configs/parameters/long_open_lock.yaml
index 56fa608..eced007 100644
--- a/configs/parameters/long_open_lock.yaml
+++ b/configs/parameters/long_open_lock.yaml
@@ -85,3 +85,4 @@ train:
   device: "cuda"
   gpu: 0
   name: "long_open_lock"
+  wandb_name: ManiSkill_ViTac
\ No newline at end of file
diff --git a/configs/parameters/peg_insertion.yaml b/configs/parameters/peg_insertion.yaml
index d42e567..222c467 100644
--- a/configs/parameters/peg_insertion.yaml
+++ b/configs/parameters/peg_insertion.yaml
@@ -58,11 +58,11 @@ policy:
   buffer_size: 200000
   train_freq: 2
   gradient_steps: -1
-  learning_starts: 2000
+  learning_starts: 32
   target_policy_noise: 0.5
   target_noise_clip: 1
   action_noise: 0.5
-  batch_size: 128
+  batch_size: 64
   learning_rate: 0.0003
   policy_delay: 2
 
diff --git a/envs/long_open_lock.py b/envs/long_open_lock.py
index 5aab093..759d3a4 100644
--- a/envs/long_open_lock.py
+++ b/envs/long_open_lock.py
@@ -9,12 +9,13 @@ from matplotlib import pyplot as plt
 from path import Path
 from sapienipc.ipc_utils.user_utils import ipc_update_render_all
 
-from envs.common_params import CommonParams
+
 
 script_path = os.path.dirname(os.path.realpath(__file__))
 repo_path = os.path.join(script_path, "..")
 sys.path.append(script_path)
 sys.path.append(repo_path)
+from envs.common_params import CommonParams
 import time
 from typing import List, Tuple
 
@@ -259,7 +260,8 @@ class LongOpenLockSimEnv(gym.Env):
         print(key_idx)
         if key_idx is None:
             self.index = np.random.randint(len(self.key_lock_path_list))
-            key_path, lock_path = self.key_lock_path_list[np.random.randint(len(self.key_lock_path_list))]
+            # key_path, lock_path = self.key_lock_path_list[np.random.randint(len(self.key_lock_path_list))]
+            key_path, lock_path = self.key_lock_path_list[self.index]
         else:
             assert key_idx < len(self.key_lock_path_list)
             self.index = key_idx
diff --git a/envs/peg_insertion.py b/envs/peg_insertion.py
index 260fa7b..4fd45de 100644
--- a/envs/peg_insertion.py
+++ b/envs/peg_insertion.py
@@ -951,7 +951,6 @@ if __name__ == "__main__":
         plt.savefig(filename)
         plt.close()
 
-
     offset_list = [[4, 0, 0], [-4, 0, 0], [0, 4, 0], [0, -4, 0]]
     for offset in offset_list:
         o, _ = env.reset(offset)
diff --git a/scripts/open_lock_sim_evaluation.py b/scripts/open_lock_sim_evaluation.py
index b1384ca..3e15a25 100644
--- a/scripts/open_lock_sim_evaluation.py
+++ b/scripts/open_lock_sim_evaluation.py
@@ -2,6 +2,11 @@ import copy
 import os
 import sys
 import time
+from path import Path
+script_path = os.path.dirname(os.path.realpath(__file__))
+repo_path = os.path.join(script_path, "..")
+sys.path.append(script_path)
+sys.path.insert(0, repo_path)
 import numpy as np
 import ruamel.yaml as yaml
 import torch
@@ -9,22 +14,15 @@ from stable_baselines3.common.save_util import load_from_zip_file
 
 from scripts.arguments import parse_params
 from envs.long_open_lock import LongOpenLockRandPointFlowEnv
-from path import Path
+
 from stable_baselines3.common.utils import set_random_seed
 
 from solutions.policies import TD3PolicyForLongOpenLockPointFlowEnv
 from utils.common import get_time, get_average_params
 from loguru import logger
 
-script_path = os.path.dirname(os.path.realpath(__file__))
-repo_path = os.path.join(script_path, "..")
-sys.path.append(script_path)
-sys.path.insert(0, repo_path)
 
-script_path = os.path.dirname(os.path.realpath(__file__))
-repo_path = os.path.join(script_path, "..")
-sys.path.append(script_path)
-sys.path.insert(0, repo_path)
+
 
 EVAL_CFG_FILE = os.path.join(repo_path, "configs/evaluation/open_lock_evaluation.yaml")
 KEY_NUM = 4
@@ -121,7 +119,7 @@ if __name__ == "__main__":
     key = args.key
     # replace the model with your own policy
 
-    policy_file = "../pretrain_weight/pretrain_openlock/best_model.zip"
+    policy_file = "./pretrain_weight/pretrain_openlock/best_model"
     data, params, _ = load_from_zip_file(policy_file)
     model = TD3PolicyForLongOpenLockPointFlowEnv(observation_space=data["observation_space"],
                                     action_space=data["action_space"],
diff --git a/scripts/universal_training_script.py b/scripts/universal_training_script.py
index 1738c03..86b577b 100644
--- a/scripts/universal_training_script.py
+++ b/scripts/universal_training_script.py
@@ -14,6 +14,7 @@ from path import Path
 from solutions.policies import (
     TD3PolicyForPointFlowEnv, TD3PolicyForLongOpenLockPointFlowEnv
 )
+
 from stable_baselines3 import TD3
 from stable_baselines3.common.callbacks import (CallbackList,
                                                 CheckpointCallback,
@@ -24,6 +25,7 @@ from utils.common import get_time
 from wandb.integration.sb3 import WandbCallback
 
 import wandb
+
 from arguments import *
 
 algorithm_aliases = {
@@ -51,6 +53,8 @@ def make_env(env_name, seed=0, i=0, **env_args):
 if __name__ == "__main__":
     parser = get_parser()
     args = parser.parse_args()
+    # args.cfg='configs/parameters/peg_insertion.yaml'
+    args.cfg='configs/parameters/long_open_lock.yaml'
     with open(args.cfg, "r") as f:
         cfg = yaml.YAML(typ='safe', pure=True).load(f)
 
@@ -146,12 +150,11 @@ if __name__ == "__main__":
         n_eval_episodes=cfg["train"]["n_eval"],
     )
 
-    WANDB = False
+    WANDB = True
     if WANDB:
         wandb_run = wandb.init(
             project=cfg["train"]["wandb_name"],
             name=f"{cfg['train']['name']}_{exp_start_time}",
-            entity="openlock",
             config=cfg,
             sync_tensorboard=True,
             monitor_gym=False,
diff --git a/solutions/actor_and_critics.py b/solutions/actor_and_critics.py
index 6445222..d00d423 100644
--- a/solutions/actor_and_critics.py
+++ b/solutions/actor_and_critics.py
@@ -79,9 +79,9 @@ class PointNetActor(Actor):
         l_point_flow_fea = point_flow_fea[:batch_num, ...]
         r_point_flow_fea = point_flow_fea[batch_num:, ...]
 
-        point_flow_fea = torch.cat([l_point_flow_fea, r_point_flow_fea], dim=-1)
+        point_flow_fea = torch.cat([l_point_flow_fea, r_point_flow_fea], dim=-1) # [2*64]
 
-        pred = self.mlp_policy(point_flow_fea)
+        pred = self.mlp_policy(point_flow_fea) # [2*3]
 
         return pred
 
diff --git a/solutions/networks.py b/solutions/networks.py
index 8e6f27e..9b780c6 100644
--- a/solutions/networks.py
+++ b/solutions/networks.py
@@ -39,11 +39,11 @@ class PointNetFea(nn.Module):
         return x
 
 
-class PointNetFeaNew(nn.Module):
+class PointNetFeaNew(nn.Module): # 64->128->512
     def __init__(self, point_dim, net_layers: List, batchnorm=False):
         super(PointNetFeaNew, self).__init__()
-        self.layer_num = len(net_layers)
-        self.conv0 = nn.Conv1d(point_dim, net_layers[0], 1)
+        self.layer_num = len(net_layers) # net_layers=[64, 128, 512]
+        self.conv0 = nn.Conv1d(point_dim, net_layers[0], 1) # point_dim=64
         self.bn0 = nn.BatchNorm1d(net_layers[0]) if batchnorm else nn.Identity()
         for i in range(0, self.layer_num - 1):
             self.__setattr__(f"conv{i + 1}", nn.Conv1d(net_layers[i], net_layers[i + 1], 1))
@@ -71,15 +71,15 @@ class PointNetFeatureExtractor(nn.Module):
     need to distinguish this from other modules defined in feature_extractors.py
     those modules are only used to extract the corresponding input (e.g. point flow, manual feature, etc.) from original observations
     """
-    def __init__(self, dim, out_dim, batchnorm=False):
+    def __init__(self, dim, out_dim, batchnorm=False): # out_dim=32
         super(PointNetFeatureExtractor, self).__init__()
-        self.dim = dim
+        self.dim = dim # 4
 
         self.pointnet_local_feature_num = 64
         self.pointnet_global_feature_num = 512
         # self.mlp_feature_num = 256  # self.pointnet_global_feature_num  #256
 
-        self.pointnet_local_fea = nn.Sequential(
+        self.pointnet_local_fea = nn.Sequential( # 4->64->64->64
             nn.Conv1d(dim, self.pointnet_local_feature_num, 1),
             nn.BatchNorm1d(self.pointnet_local_feature_num) if batchnorm else nn.Identity(),
             nn.ReLU(),
@@ -87,7 +87,7 @@ class PointNetFeatureExtractor(nn.Module):
             nn.BatchNorm1d(self.pointnet_local_feature_num) if batchnorm else nn.Identity(),
             nn.ReLU(),
         )
-        self.pointnet_global_fea = PointNetFeaNew(self.pointnet_local_feature_num, [64, 128, self.pointnet_global_feature_num], batchnorm=batchnorm)
+        self.pointnet_global_fea = PointNetFeaNew(self.pointnet_local_feature_num, [64, 128, self.pointnet_global_feature_num], batchnorm=batchnorm) # 64->128->512
         # self.pointnet_total_fea = PointNetFeaNew(
         #     self.pointnet_local_feature_num + self.pointnet_global_feature_num, [512, self.mlp_feature_num], batchnorm=batchnorm
         # )
@@ -101,18 +101,18 @@ class PointNetFeatureExtractor(nn.Module):
         :param marker_pos: Tensor, size (batch, num_points, 4)
         :return:
         """
-        if marker_pos.ndim == 2:
+        if marker_pos.ndim == 2: # marker_pos：torch.Size([128, 128, 4])
             marker_pos = torch.unsqueeze(marker_pos, dim=0)
 
-        marker_pos = torch.transpose(marker_pos, 1, 2)
+        marker_pos = torch.transpose(marker_pos, 1, 2) # torch.Size([128, 4, 128]) 特征维放到第二个位置
 
-        batch_num = marker_pos.shape[0]
-        point_num = marker_pos.shape[2]
+        # batch_num = marker_pos.shape[0] # 128
+        # point_num = marker_pos.shape[2] # 128
 
-        local_feature = self.pointnet_local_fea(marker_pos)  # (batch_num, self.pointnet_local_feature_num, point_num)
+        local_feature = self.pointnet_local_fea(marker_pos)  # (batch_num, self.pointnet_local_feature_num, point_num) torch.Size([128, 64, 128])
         # shape: (batch, step * 2, num_points)
         global_feature = self.pointnet_global_fea(local_feature).view(
-            -1, self.pointnet_global_feature_num)  # (batch_num, self.pointnet_global_feature_num)
+            -1, self.pointnet_global_feature_num)  # (batch_num, self.pointnet_global_feature_num) # torch.Size([128, 512])
 
         # global_feature = global_feature.repeat(
         #     (1, 1, point_num)
