wandb_version: 1

env:
  desc: null
  value:
    step_penalty: 1
    final_reward: 10
    max_action:
    - 2.0
    - 2.0
    - 4.0
    max_steps: 8
    z_step_size: 0.125
    peg_hole_path_file: configs/peg_insertion/3shape_1.5mm.txt
    peg_x_max_offset: 5.0
    peg_y_max_offset: 5.0
    peg_theta_max_offset: 10.0
    marker_interval_range:
    - 1.95
    - 2.15
    marker_rotation_range: 0.1
    marker_translation_range:
    - 1
    - 1
    marker_pos_shift_range:
    - 0.1
    - 0.1
    marker_random_noise: 0.5
    marker_lose_tracking_probability: 0.01
    normalize: false
policy:
  desc: null
  value:
    buffer_size: 200000
    train_freq: 2
    gradient_steps: -1
    learning_starts: 2000
    action_noise: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5
      0.5])), n_envs=12)
    batch_size: 512
    learning_rate: 0.0001
    optimize_memory_usage: false
    ent_coef: auto
    target_update_interval: 1
    target_entropy: auto
    use_sde: false
    sde_sample_freq: -1
    use_sde_at_warmup: false
    policy_kwargs:
      pointnet_in_dim: 4
      pointnet_out_dim: 32
      pointnet_batchnorm: false
      pointnet_layernorm: true
      zero_init_output: true
      use_sde: false
    device: cuda:0
    seed: 0
    tensorboard_log: /media/lab/data/yzk/ManiSkill-ViTac2024/scripts/../training_log/3shape_1.5mm_batch_size_512_lr_0.0001_2024-03-17_21-56-13.542
train:
  desc: null
  value:
    total_timesteps: 500000
    log_interval: 10
    checkpoint_every: 2000
    eval_freq: 2000
    n_eval: 50
    parallel: 12
    seed: 0
    device: cuda:0
    gpu: 0
    name: 3shape_1.5mm_batch_size_512_lr_0.0001
    wandb_name: ManiSkill_ViTac
    emp: {}
cfg:
  desc: null
  value: configs/parameters/peg_insertion_sac.yaml
no_render:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    code_path: code/scripts/train_sac.py
    python_version: 3.10.0
    cli_version: 0.16.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1710683779.861061
    t:
      1:
      - 1
      - 5
      - 53
      - 55
      2:
      - 1
      - 5
      - 53
      - 55
      3:
      - 13
      - 16
      - 22
      - 23
      - 35
      4: 3.10.0
      5: 0.16.0
      8:
      - 5
      13: linux-x86_64
algo:
  desc: null
  value: SAC
policy_class:
  desc: null
  value: <class 'solutions.policies_sac.SACPolicyForPointFlowEnv'>
device:
  desc: null
  value: cuda:0
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{''pointnet_in_dim'': 4, ''pointnet_out_dim'': 32, ''pointnet_batchnorm'':
    False, ''pointnet_layernorm'': True, ''zero_init_output'': True, ''use_sde'':
    False}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 500000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: 0
action_noise:
  desc: null
  value: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5 0.5])), n_envs=12)
start_time:
  desc: null
  value: 1710683784444481268
learning_rate:
  desc: null
  value: 0.0001
tensorboard_log:
  desc: null
  value: /media/lab/data/yzk/ManiSkill-ViTac2024/scripts/../training_log/3shape_1.5mm_batch_size_512_lr_0.0001_2024-03-17_21-56-13.542
_last_obs:
  desc: null
  value: "OrderedDict([('gt_offset', array([[-3.229588  , -3.883562  , -7.039751 \
    \ ],\n       [-1.3341608 , -1.4223145 ,  0.40586135],\n       [ 4.0509095 ,  2.9261267\
    \ , -9.838933  ],\n       [-2.62231   , -3.75208   , -2.502655  ],\n       [ 3.3844678\
    \ , -0.29480934, -1.2058337 ],\n       [ 4.6590276 ,  3.8934438 ,  2.8763995 ],\n\
    \       [ 0.4123667 , -1.8342502 ,  0.22375657],\n       [ 3.3993812 ,  1.0523556\
    \ ,  0.5579632 ],\n       [ 0.3296736 , -3.0611951 ,  0.23696543],\n       [-3.984523\
    \  , -1.7598487 , -3.4501905 ],\n       [-1.4203128 , -1.7320957 ,  7.10161  \
    \ ],\n       [-3.8207278 ,  3.5233376 , -0.9167456 ]], dtype=float32)), ('marker_flow',\
    \ array([[[[[ 29.05804  ,  13.605795 ],\n          [ 59.47117  ,  12.751727 ],\n\
    \          [ 28.594843 ,  46.976795 ],\n          ...,\n          [298.9215  \
    \ , 210.55003  ],\n          [298.9215   , 210.55003  ],\n          [298.9215\
    \   , 210.55003  ]],\n\n         [[ 31.50101  ,  12.434861 ],\n          [ 63.2108\
    \   ,  13.517076 ],\n          [ 31.600994 ,  45.495724 ],\n          ...,\n \
    \         [302.29196  , 212.66583  ],\n          [302.29196  , 212.66583  ],\n\
    \          [302.29196  , 212.66583  ]]],\n\n\n        [[[269.3756   ,  14.792277\
    \ ],\n          [301.99622  ,  15.370403 ],\n          [  8.930889 ,  33.49985\
    \  ],\n          ...,\n          [289.95923  , 231.0528   ],\n          [289.95923\
    \  , 231.0528   ],\n          [289.95923  , 231.0528   ]],\n\n         [[272.999\
    \    ,  14.269595 ],\n          [306.5464   ,  15.760851 ],\n          [ 12.168673\
    \ ,  32.574867 ],\n          ...,\n          [294.01337  , 231.84943  ],\n   \
    \       [294.01337  , 231.84943  ],\n          [294.01337  , 231.84943  ]]]],\n\
    \n\n\n       [[[[ 34.72734  ,  26.52366  ],\n          [ 67.29883  ,  26.31661\
    \  ],\n          [101.788864 ,  25.714996 ],\n          ...,\n          [307.21634\
    \  , 205.08932  ],\n          [307.21634  , 205.08932  ],\n          [307.21634\
    \  , 205.08932  ]],\n\n         [[ 36.398506 ,  26.963873 ],\n          [ 69.39496\
    \  ,  25.810131 ],\n          [102.788765 ,  24.307564 ],\n          ...,\n  \
    \        [309.34128  , 202.49185  ],\n          [309.34128  , 202.49185  ],\n\
    \          [309.34128  , 202.49185  ]]],\n\n\n        [[[ 20.839548 ,  39.959667\
    \ ],\n          [ 54.578175 ,  40.711864 ],\n          [ 86.14165  ,  36.536674\
    \ ],\n          ...,\n          [291.98468  , 216.09709  ],\n          [291.98468\
    \  , 216.09709  ],\n          [291.98468  , 216.09709  ]],\n\n         [[ 23.55063\
    \  ,  40.50189  ],\n          [ 56.84072  ,  40.3521   ],\n          [ 89.284195\
    \ ,  37.583103 ],\n          ...,\n          [295.88046  , 215.49295  ],\n   \
    \       [295.88046  , 215.49295  ],\n          [295.88046  , 215.49295  ]]]],\n\
    \n\n\n       [[[[  5.381889 ,  22.16517  ],\n          [ 37.953934 ,  25.41032\
    \  ],\n          [ 69.70814  ,  25.857538 ],\n          ...,\n          [296.9084\
    \   , 224.68013  ],\n          [296.9084   , 224.68013  ],\n          [296.9084\
    \   , 224.68013  ]],\n\n         [[  9.053697 ,  22.131987 ],\n          [ 41.040348\
    \ ,  24.850595 ],\n          [ 74.90119  ,  24.893951 ],\n          ...,\n   \
    \       [300.8819   , 225.65569  ],\n          [300.8819   , 225.65569  ],\n \
    \         [300.8819   , 225.65569  ]]],\n\n\n        [[[ 25.764767 ,  29.132269\
    \ ],\n          [ 57.115887 ,  27.943018 ],\n          [ 90.67519  ,  22.975605\
    \ ],\n          ...,\n          [298.8656   , 224.68604  ],\n          [298.8656\
    \   , 224.68604  ],\n          [298.8656   , 224.68604  ]],\n\n         [[ 29.198044\
    \ ,  29.497103 ],\n          [ 59.858765 ,  28.266916 ],\n          [ 92.913124\
    \ ,  23.45162  ],\n          ...,\n          [303.0823   , 224.41199  ],\n   \
    \       [303.0823   , 224.41199  ],\n          [303.0823   , 224.41199  ]]]],\n\
    \n\n\n       ...,\n\n\n\n       [[[[ 34.991817 ,  25.12373  ],\n          [ 70.32696\
    \  ,  26.091843 ],\n          [104.127625 ,  27.89282  ],\n          ...,\n  \
    \        [297.7279   , 220.4904   ],\n          [297.7279   , 220.4904   ],\n\
    \          [297.7279   , 220.4904   ]],\n\n         [[ 38.126434 ,  23.285967\
    \ ],\n          [ 73.4515   ,  26.437937 ],\n          [107.19773  ,  28.048655\
    \ ],\n          ...,\n          [301.45792  , 220.11382  ],\n          [301.45792\
    \  , 220.11382  ],\n          [301.45792  , 220.11382  ]]],\n\n\n        [[[ 57.72738\
    \  ,  18.994482 ],\n          [ 90.6435   ,  19.514135 ],\n          [153.03725\
    \  ,  16.128511 ],\n          ...,\n          [283.84845  , 225.15378  ],\n  \
    \        [283.84845  , 225.15378  ],\n          [283.84845  , 225.15378  ]],\n\
    \n         [[ 60.48503  ,  18.237888 ],\n          [ 94.24023  ,  18.013855 ],\n\
    \          [156.42943  ,  15.838924 ],\n          ...,\n          [286.6396  \
    \ , 225.71057  ],\n          [286.6396   , 225.71057  ],\n          [286.6396\
    \   , 225.71057  ]]]],\n\n\n\n       [[[[127.203545 ,  13.420517 ],\n        \
    \  [161.73582  ,  15.349607 ],\n          [194.80328  ,  15.64021  ],\n      \
    \    ...,\n          [ 47.62962  , 237.32289  ],\n          [ 47.62962  , 237.32289\
    \  ],\n          [ 47.62962  , 237.32289  ]],\n\n         [[129.86205  ,  14.007199\
    \ ],\n          [164.72168  ,  15.032881 ],\n          [197.33224  ,  15.080766\
    \ ],\n          ...,\n          [ 51.21211  , 236.02713  ],\n          [ 51.21211\
    \  , 236.02713  ],\n          [ 51.21211  , 236.02713  ]]],\n\n\n        [[[ 10.046502\
    \ ,  18.191242 ],\n          [ 39.90371  ,  15.8140955],\n          [ 73.05177\
    \  ,  13.794077 ],\n          ...,\n          [303.79333  , 221.36165  ],\n  \
    \        [303.79333  , 221.36165  ],\n          [303.79333  , 221.36165  ]],\n\
    \n         [[ 13.722445 ,  18.311829 ],\n          [ 43.547596 ,  17.111479 ],\n\
    \          [ 75.42594  ,  12.900705 ],\n          ...,\n          [307.4159  \
    \ , 220.42653  ],\n          [307.4159   , 220.42653  ],\n          [307.4159\
    \   , 220.42653  ]]]],\n\n\n\n       [[[[ 22.48357  ,  26.527296 ],\n        \
    \  [ 53.53347  ,  26.99417  ],\n          [ 87.23809  ,  27.807375 ],\n      \
    \    ...,\n          [283.0832   , 213.24483  ],\n          [283.0832   , 213.24483\
    \  ],\n          [283.0832   , 213.24483  ]],\n\n         [[ 26.27279  ,  25.733368\
    \ ],\n          [ 56.11133  ,  26.703365 ],\n          [ 90.71187  ,  27.176771\
    \ ],\n          ...,\n          [286.5697   , 213.16406  ],\n          [286.5697\
    \   , 213.16406  ],\n          [286.5697   , 213.16406  ]]],\n\n\n        [[[\
    \ 70.450935 ,  14.152883 ],\n          [102.05878  ,  14.914469 ],\n         \
    \ [137.2676   ,  17.211264 ],\n          ...,\n          [294.3337   , 225.35963\
    \  ],\n          [294.3337   , 225.35963  ],\n          [294.3337   , 225.35963\
    \  ]],\n\n         [[ 72.20915  ,  14.955546 ],\n          [105.28884  ,  14.079592\
    \ ],\n          [141.03656  ,  17.277822 ],\n          ...,\n          [297.11343\
    \  , 224.78267  ],\n          [297.11343  , 224.78267  ],\n          [297.11343\
    \  , 224.78267  ]]]]], dtype=float32))])"
_last_episode_starts:
  desc: null
  value: '[ True  True  True  True  True  True  True  True  True  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: 'Dict(''gt_offset'': Box(-3.4028235e+38, 3.4028235e+38, (3,), float32), ''marker_flow'':
    Box(-3.4028235e+38, 3.4028235e+38, (2, 2, 128, 2), float32))'
action_space:
  desc: null
  value: Box(-1.0, 1.0, (3,), float32)
n_envs:
  desc: null
  value: 12
buffer_size:
  desc: null
  value: 200000
batch_size:
  desc: null
  value: 512
learning_starts:
  desc: null
  value: 2000
tau:
  desc: null
  value: 0.005
gamma:
  desc: null
  value: 0.99
gradient_steps:
  desc: null
  value: -1
optimize_memory_usage:
  desc: null
  value: 'False'
replay_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.DictReplayBuffer object at 0x7f57d889c910>
replay_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.DictReplayBuffer'>
replay_buffer_kwargs:
  desc: null
  value: '{}'
_episode_storage:
  desc: null
  value: None
train_freq:
  desc: null
  value: 'TrainFreq(frequency=2, unit=<TrainFrequencyUnit.STEP: ''step''>)'
use_sde_at_warmup:
  desc: null
  value: 'False'
target_entropy:
  desc: null
  value: -3.0
log_ent_coef:
  desc: null
  value: tensor([0.], device='cuda:0', requires_grad=True)
ent_coef:
  desc: null
  value: auto
target_update_interval:
  desc: null
  value: 1
ent_coef_optimizer:
  desc: null
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay:\
    \ 0\n)"
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x7f57d8869d80>
actor:
  desc: null
  value: "Actor(\n  (features_extractor): FeatureExtractorWithPointNetEncoder(\n \
    \   (feature_extractor_net): PointNetFeatureExtractor(\n      (pointnet_local_fea):\
    \ Sequential(\n        (0): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n   \
    \     (1): Identity()\n        (2): ReLU()\n        (3): Conv1d(64, 64, kernel_size=(1,),\
    \ stride=(1,))\n        (4): Identity()\n        (5): ReLU()\n      )\n      (pointnet_global_fea):\
    \ PointNetFeaNew(\n        (conv0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n\
    \        (bn0): Identity()\n        (conv1): Conv1d(64, 128, kernel_size=(1,),\
    \ stride=(1,))\n        (bn1): Identity()\n        (conv2): Conv1d(128, 512, kernel_size=(1,),\
    \ stride=(1,))\n        (bn2): Identity()\n      )\n      (mlp_output): Sequential(\n\
    \        (0): Linear(in_features=512, out_features=256, bias=True)\n        (1):\
    \ ReLU()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \        (3): ReLU()\n        (4): Linear(in_features=256, out_features=32, bias=True)\n\
    \      )\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=64,\
    \ out_features=256, bias=True)\n    (1): Identity()\n    (2): ReLU()\n    (3):\
    \ Linear(in_features=256, out_features=256, bias=True)\n    (4): Identity()\n\
    \    (5): ReLU()\n    (6): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (7): Tanh()\n  )\n  (mu): Linear(in_features=256, out_features=3, bias=True)\n\
    \  (log_std): Linear(in_features=256, out_features=3, bias=True)\n)"
critic:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
critic_target:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
batch_norm_stats:
  desc: null
  value: '[]'
batch_norm_stats_target:
  desc: null
  value: '[]'
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7f57d0bbcfd0>
