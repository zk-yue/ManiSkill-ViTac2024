diff --git a/.gitignore b/.gitignore
old mode 100644
new mode 100755
diff --git a/LICENSE b/LICENSE
old mode 100644
new mode 100755
diff --git a/README.md b/README.md
old mode 100644
new mode 100755
diff --git a/assets/gelsight_mini_e430/active.txt b/assets/gelsight_mini_e430/active.txt
old mode 100644
new mode 100755
diff --git a/assets/gelsight_mini_e430/faces.txt b/assets/gelsight_mini_e430/faces.txt
old mode 100644
new mode 100755
diff --git a/assets/gelsight_mini_e430/meta_file b/assets/gelsight_mini_e430/meta_file
old mode 100644
new mode 100755
diff --git a/assets/gelsight_mini_e430/on_surface.txt b/assets/gelsight_mini_e430/on_surface.txt
old mode 100644
new mode 100755
diff --git a/assets/gelsight_mini_e430/tet.msh b/assets/gelsight_mini_e430/tet.msh
old mode 100644
new mode 100755
diff --git a/assets/key_lock/key1.STL b/assets/key_lock/key1.STL
old mode 100644
new mode 100755
diff --git a/assets/key_lock/key1_tet.msh b/assets/key_lock/key1_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/key_lock/key2.STL b/assets/key_lock/key2.STL
old mode 100644
new mode 100755
diff --git a/assets/key_lock/key2_tet.msh b/assets/key_lock/key2_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/key_lock/key3.STL b/assets/key_lock/key3.STL
old mode 100644
new mode 100755
diff --git a/assets/key_lock/key3_tet.msh b/assets/key_lock/key3_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/key_lock/key4.STL b/assets/key_lock/key4.STL
old mode 100644
new mode 100755
diff --git a/assets/key_lock/key4_tet.msh b/assets/key_lock/key4_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/key_lock/lock_core_sim1.STL b/assets/key_lock/lock_core_sim1.STL
old mode 100644
new mode 100755
diff --git a/assets/key_lock/lock_core_sim1_tet.msh b/assets/key_lock/lock_core_sim1_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/key_lock/lock_core_sim2.STL b/assets/key_lock/lock_core_sim2.STL
old mode 100644
new mode 100755
diff --git a/assets/key_lock/lock_core_sim2_tet.msh b/assets/key_lock/lock_core_sim2_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/key_lock/lock_core_sim3.STL b/assets/key_lock/lock_core_sim3.STL
old mode 100644
new mode 100755
diff --git a/assets/key_lock/lock_core_sim3_tet.msh b/assets/key_lock/lock_core_sim3_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/key_lock/lock_core_sim4.STL b/assets/key_lock/lock_core_sim4.STL
old mode 100644
new mode 100755
diff --git a/assets/key_lock/lock_core_sim4_tet.msh b/assets/key_lock/lock_core_sim4_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_0.5mm.STL b/assets/peg_in_hole/concave1_hole_0.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_0.5mm_tet.msh b/assets/peg_in_hole/concave1_hole_0.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_1.0mm.STL b/assets/peg_in_hole/concave1_hole_1.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_1.0mm_tet.msh b/assets/peg_in_hole/concave1_hole_1.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_1.5mm.STL b/assets/peg_in_hole/concave1_hole_1.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_1.5mm_tet.msh b/assets/peg_in_hole/concave1_hole_1.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_2.0mm.STL b/assets/peg_in_hole/concave1_hole_2.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_2.0mm_tet.msh b/assets/peg_in_hole/concave1_hole_2.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_2.5mm.STL b/assets/peg_in_hole/concave1_hole_2.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_hole_2.5mm_tet.msh b/assets/peg_in_hole/concave1_hole_2.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_peg.STL b/assets/peg_in_hole/concave1_peg.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave1_peg_tet.msh b/assets/peg_in_hole/concave1_peg_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_hole_0.5mm.STL b/assets/peg_in_hole/concave2_hole_0.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_hole_0.5mm_tet.msh b/assets/peg_in_hole/concave2_hole_0.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_hole_1.0mm.STL b/assets/peg_in_hole/concave2_hole_1.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_hole_1.0mm_tet.msh b/assets/peg_in_hole/concave2_hole_1.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_hole_1.5mm.STL b/assets/peg_in_hole/concave2_hole_1.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_hole_1.5mm_tet.msh b/assets/peg_in_hole/concave2_hole_1.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_hole_2.5mm.STL b/assets/peg_in_hole/concave2_hole_2.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_hole_2.5mm_tet.msh b/assets/peg_in_hole/concave2_hole_2.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_peg.STL b/assets/peg_in_hole/concave2_peg.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/concave2_peg_tet.msh b/assets/peg_in_hole/concave2_peg_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/convex_hole_0.5mm.STL b/assets/peg_in_hole/convex_hole_0.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/convex_hole_0.5mm_tet.msh b/assets/peg_in_hole/convex_hole_0.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/convex_hole_1.0mm.STL b/assets/peg_in_hole/convex_hole_1.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/convex_hole_1.0mm_tet.msh b/assets/peg_in_hole/convex_hole_1.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/convex_hole_1.5mm.STL b/assets/peg_in_hole/convex_hole_1.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/convex_hole_1.5mm_tet.msh b/assets/peg_in_hole/convex_hole_1.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/convex_hole_2.5mm.STL b/assets/peg_in_hole/convex_hole_2.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/convex_hole_2.5mm_tet.msh b/assets/peg_in_hole/convex_hole_2.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/convex_peg_tet.msh b/assets/peg_in_hole/convex_peg_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_0.5mm.STL b/assets/peg_in_hole/cuboid_hole_0.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_0.5mm_tet.msh b/assets/peg_in_hole/cuboid_hole_0.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_1.0mm.STL b/assets/peg_in_hole/cuboid_hole_1.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_1.0mm_tet.msh b/assets/peg_in_hole/cuboid_hole_1.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_1.5mm.STL b/assets/peg_in_hole/cuboid_hole_1.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_1.5mm_tet.msh b/assets/peg_in_hole/cuboid_hole_1.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_2.0mm.STL b/assets/peg_in_hole/cuboid_hole_2.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_2.0mm_tet.msh b/assets/peg_in_hole/cuboid_hole_2.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_2.5mm.STL b/assets/peg_in_hole/cuboid_hole_2.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_hole_2.5mm_tet.msh b/assets/peg_in_hole/cuboid_hole_2.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_peg.STL b/assets/peg_in_hole/cuboid_peg.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/cuboid_peg_tet.msh b/assets/peg_in_hole/cuboid_peg_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_hole_0.5mm.STL b/assets/peg_in_hole/hexagon_hole_0.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_hole_0.5mm_tet.msh b/assets/peg_in_hole/hexagon_hole_0.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_hole_1.0mm.STL b/assets/peg_in_hole/hexagon_hole_1.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_hole_1.0mm_tet.msh b/assets/peg_in_hole/hexagon_hole_1.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_hole_1.5mm.STL b/assets/peg_in_hole/hexagon_hole_1.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_hole_1.5mm_tet.msh b/assets/peg_in_hole/hexagon_hole_1.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_hole_2.5mm.STL b/assets/peg_in_hole/hexagon_hole_2.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_hole_2.5mm_tet.msh b/assets/peg_in_hole/hexagon_hole_2.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_peg.STL b/assets/peg_in_hole/hexagon_peg.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/hexagon_peg_tet.msh b/assets/peg_in_hole/hexagon_peg_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/octagon_hole_0.5mm.STL b/assets/peg_in_hole/octagon_hole_0.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/octagon_hole_0.5mm_tet.msh b/assets/peg_in_hole/octagon_hole_0.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/octagon_hole_1.0mm.STL b/assets/peg_in_hole/octagon_hole_1.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/octagon_hole_1.0mm_tet.msh b/assets/peg_in_hole/octagon_hole_1.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/octagon_hole_1.5mm.STL b/assets/peg_in_hole/octagon_hole_1.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/octagon_hole_1.5mm_tet.msh b/assets/peg_in_hole/octagon_hole_1.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/octagon_hole_2.5mm.STL b/assets/peg_in_hole/octagon_hole_2.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/octagon_hole_2.5mm_tet.msh b/assets/peg_in_hole/octagon_hole_2.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/octagon_peg_tet.msh b/assets/peg_in_hole/octagon_peg_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_0.5mm.STL b/assets/peg_in_hole/trapezoid_hole_0.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_0.5mm_tet.msh b/assets/peg_in_hole/trapezoid_hole_0.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_1.0mm.STL b/assets/peg_in_hole/trapezoid_hole_1.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_1.0mm_tet.msh b/assets/peg_in_hole/trapezoid_hole_1.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_1.5mm.STL b/assets/peg_in_hole/trapezoid_hole_1.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_1.5mm_tet.msh b/assets/peg_in_hole/trapezoid_hole_1.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_2.0mm.STL b/assets/peg_in_hole/trapezoid_hole_2.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_2.0mm_tet.msh b/assets/peg_in_hole/trapezoid_hole_2.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_2.5mm.STL b/assets/peg_in_hole/trapezoid_hole_2.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_2.5mm_tet.msh b/assets/peg_in_hole/trapezoid_hole_2.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_hole_2.5mm_tetra.pkl b/assets/peg_in_hole/trapezoid_hole_2.5mm_tetra.pkl
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_peg_tet.msh b/assets/peg_in_hole/trapezoid_peg_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/trapezoid_peg_tetra.pkl b/assets/peg_in_hole/trapezoid_peg_tetra.pkl
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_hole_0.5mm.STL b/assets/peg_in_hole/triangle_hole_0.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_hole_0.5mm_tet.msh b/assets/peg_in_hole/triangle_hole_0.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_hole_1.0mm.STL b/assets/peg_in_hole/triangle_hole_1.0mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_hole_1.0mm_tet.msh b/assets/peg_in_hole/triangle_hole_1.0mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_hole_1.5mm.STL b/assets/peg_in_hole/triangle_hole_1.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_hole_1.5mm_tet.msh b/assets/peg_in_hole/triangle_hole_1.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_hole_2.5mm.STL b/assets/peg_in_hole/triangle_hole_2.5mm.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_hole_2.5mm_tet.msh b/assets/peg_in_hole/triangle_hole_2.5mm_tet.msh
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_peg.STL b/assets/peg_in_hole/triangle_peg.STL
old mode 100644
new mode 100755
diff --git a/assets/peg_in_hole/triangle_peg_tet.msh b/assets/peg_in_hole/triangle_peg_tet.msh
old mode 100644
new mode 100755
diff --git a/configs/evaluation/open_lock_evaluation.yaml b/configs/evaluation/open_lock_evaluation.yaml
old mode 100644
new mode 100755
diff --git a/configs/evaluation/peg_insertion_evaluation.yaml b/configs/evaluation/peg_insertion_evaluation.yaml
old mode 100644
new mode 100755
index 1e57704..9acaebe
--- a/configs/evaluation/peg_insertion_evaluation.yaml
+++ b/configs/evaluation/peg_insertion_evaluation.yaml
@@ -43,7 +43,7 @@ env:
     tac_poisson_ratio_l: [0.3, 0.3]
     tac_poisson_ratio_r: [0.3, 0.3]
     tac_sensor_meta_file: gelsight_mini_e430/meta_file
-  peg_hole_path_file: configs/peg_insertion/3shape_1.5mm.txt
+  peg_hole_path_file: configs/peg_insertion/3shape_2.0mm.txt
   peg_theta_max_offset: 10.0
   peg_x_max_offset: 5.0
   peg_y_max_offset: 5.0
diff --git a/configs/key_and_lock/key_lock.txt b/configs/key_and_lock/key_lock.txt
old mode 100644
new mode 100755
diff --git a/configs/parameters/long_open_lock.yaml b/configs/parameters/long_open_lock.yaml
old mode 100644
new mode 100755
index 56fa608..7b2e62c
--- a/configs/parameters/long_open_lock.yaml
+++ b/configs/parameters/long_open_lock.yaml
@@ -3,7 +3,7 @@ env:
   max_action: [4.0, 2.0, 2.0]
   step_penalty: 1
   final_reward: 10
-  max_steps: 100
+  max_steps: 10
   sensor_offset_x_range_len: 2.0
   sensor_offset_z_range_len: 2.0
   key_x_max_offset: 10
@@ -52,7 +52,7 @@ env:
     lock_friction: [ 0.0, 1.0 ]
 policy:
   policy_name: TD3PolicyForLongOpenLockPointFlowEnv
-  buffer_size: 200000
+  buffer_size: 20000
   train_freq: 2
   gradient_steps: -1
   learning_starts: 2000
@@ -85,3 +85,4 @@ train:
   device: "cuda"
   gpu: 0
   name: "long_open_lock"
+  wandb_name: ManiSkill_ViTac
\ No newline at end of file
diff --git a/configs/parameters/peg_insertion.yaml b/configs/parameters/peg_insertion.yaml
old mode 100644
new mode 100755
index d42e567..222c467
--- a/configs/parameters/peg_insertion.yaml
+++ b/configs/parameters/peg_insertion.yaml
@@ -58,11 +58,11 @@ policy:
   buffer_size: 200000
   train_freq: 2
   gradient_steps: -1
-  learning_starts: 2000
+  learning_starts: 32
   target_policy_noise: 0.5
   target_noise_clip: 1
   action_noise: 0.5
-  batch_size: 128
+  batch_size: 64
   learning_rate: 0.0003
   policy_delay: 2
 
diff --git a/configs/peg_insertion/1shape_2.0mm.txt b/configs/peg_insertion/1shape_2.0mm.txt
old mode 100644
new mode 100755
diff --git a/configs/peg_insertion/3shape_1.0mm.txt b/configs/peg_insertion/3shape_1.0mm.txt
old mode 100644
new mode 100755
diff --git a/configs/peg_insertion/3shape_1.5mm.txt b/configs/peg_insertion/3shape_1.5mm.txt
old mode 100644
new mode 100755
diff --git a/configs/peg_insertion/7shape_1.0mm.txt b/configs/peg_insertion/7shape_1.0mm.txt
old mode 100644
new mode 100755
diff --git a/configs/peg_insertion/7shape_1.5mm.txt b/configs/peg_insertion/7shape_1.5mm.txt
old mode 100644
new mode 100755
diff --git a/envs/__init__.py b/envs/__init__.py
old mode 100644
new mode 100755
diff --git a/envs/common_params.py b/envs/common_params.py
old mode 100644
new mode 100755
diff --git a/envs/gelsight_mini_bg.png b/envs/gelsight_mini_bg.png
old mode 100644
new mode 100755
diff --git a/envs/long_open_lock.py b/envs/long_open_lock.py
old mode 100644
new mode 100755
index 5aab093..6b95ef1
--- a/envs/long_open_lock.py
+++ b/envs/long_open_lock.py
@@ -9,12 +9,12 @@ from matplotlib import pyplot as plt
 from path import Path
 from sapienipc.ipc_utils.user_utils import ipc_update_render_all
 
-from envs.common_params import CommonParams
-
 script_path = os.path.dirname(os.path.realpath(__file__))
 repo_path = os.path.join(script_path, "..")
 sys.path.append(script_path)
 sys.path.append(repo_path)
+
+from envs.common_params import CommonParams
 import time
 from typing import List, Tuple
 
@@ -31,7 +31,7 @@ from envs.tactile_sensor_sapienipc import (TactileSensorSapienIPC,
 from utils.common import Params, randomize_params, suppress_stdout_stderr
 from utils.gym_env_utils import convert_observation_to_space
 from utils.sapienipc_utils import build_sapien_entity_ABD
-
+import cv2
 wp.init()
 wp_device = wp.get_preferred_device()
 
@@ -48,21 +48,21 @@ class LongOpenLockParams(CommonParams):
                  ):
         super().__init__(**kwargs)
         self.key_lock_path_file = key_lock_path_file
-        self.indentation_depth = indentation_depth
-        self.key_friction = key_friction
+        self.indentation_depth = indentation_depth # 刻痕深度
+        self.key_friction = key_friction # 摩擦系数
         self.lock_friction = lock_friction
 
 
 class LongOpenLockSimEnv(gym.Env):
     def __init__(
             self,
-            max_action: np.ndarray,
-            step_penalty: float,
-            final_reward: float,
+            max_action: np.ndarray, #   max_action: [4.0, 2.0, 2.0]
+            step_penalty: float, # 1
+            final_reward: float, # 10
             key_x_max_offset: float = 10.0,
             key_y_max_offset: float = 0.0,
             key_z_max_offset: float = 0.0,
-            max_steps: int = 100,
+            max_steps: int = 10,
             sensor_offset_x_range_len: float = 0.0,
             senosr_offset_z_range_len: float = 0.0,
             params=None,
@@ -75,8 +75,8 @@ class LongOpenLockSimEnv(gym.Env):
 
         self.no_render = no_render
         self.index = None
-        self.step_penalty = step_penalty
-        self.final_reward = final_reward
+        self.step_penalty = step_penalty # 惩罚
+        self.final_reward = final_reward # 奖励
         self.max_steps = max_steps
         self.max_action = np.array(max_action)
         assert self.max_action.shape == (3,)
@@ -87,26 +87,34 @@ class LongOpenLockSimEnv(gym.Env):
         self.sensor_offset_x_range_len = sensor_offset_x_range_len
         self.sensor_offset_z_range_len = senosr_offset_z_range_len
 
-        self.current_episode_elapsed_steps = 0
+        self.current_episode_elapsed_steps = 0 # 当前episode已经走过的step
         self.current_episode_over = False
         self.sensor_grasp_center_init = np.array([0, 0, 0])
         self.sensor_grasp_center_current = self.sensor_grasp_center_init
 
-        if not params:
+
+        if not params: # 如果为空
             self.params_lb = LongOpenLockParams()
         else:
             self.params_lb = copy.deepcopy(params)
-        if not params_upper_bound:
+        if not params_upper_bound: #none
             self.params_ub = copy.deepcopy(self.params_lb)
         else:
             self.params_ub = copy.deepcopy(params_upper_bound)
         self.params: LongOpenLockParams = randomize_params(self.params_lb, self.params_ub)
 
-        key_lock_path_file = Path(repo_path) / self.params.key_lock_path_file
+        # key_lock_path_file="configs/key_and_lock/key_lock.txt"
+        key_lock_path_file = Path(repo_path) / self.params.key_lock_path_file  #  / 运算符来连接路径。将这两个路径连接起来，得到键锁文件的绝对路径。
         self.key_lock_path_list = []
         with open(key_lock_path_file, "r") as f:
-            for l in f.readlines():
+            for l in f.readlines(): # 使用 readlines 方法读取文件的所有行，返回一个包含每一行内容的列表。
                 self.key_lock_path_list.append([ss.strip() for ss in l.strip().split(",")])
+        # [['key_lock/key1.STL', 'key_lock/lock_core_sim1.STL'], ['key_lock/key2.STL', 'key_lock/lock_core_sim2.STL'], ['key_lock/key3.STL', 'key_lock/lock_core_sim3.STL'], ['key_lock/key4.STL', 'key_lock/lock_core_sim4.STL']]
+        # 锁和锁芯
+        # 使用 strip 方法移除行首和行尾的空白字符。
+        # 使用 split 方法以逗号为分隔符，将行内容分割成多个子字符串，得到一个列表。
+        # 对列表中的每个子字符串 ss，使用 strip 方法移除其首尾的空白字符。
+        # 将处理后的列表添加到 self.key_lock_path_list 中。
 
         self.init_left_surface_pts = None
         self.init_right_surface_pts = None
@@ -114,7 +122,7 @@ class LongOpenLockSimEnv(gym.Env):
         self.viewer = None
         if not no_render:
             self.scene = sapien.Scene()
-            self.scene.set_ambient_light([0.5, 0.5, 0.5])
+            self.scene.set_ambient_light([0.5, 0.5, 0.5]) #  环境光
             self.scene.add_directional_light([0, -1, -1], [0.5, 0.5, 0.5], True)
         else:
             self.scene = sapien.Scene(systems=[])
@@ -122,36 +130,37 @@ class LongOpenLockSimEnv(gym.Env):
         # add a camera to indicate shader
         if not no_render:
             cam_entity = sapien.Entity()
-            cam = sapien.render.RenderCameraComponent(512, 512)
+            cam = sapien.render.RenderCameraComponent(512, 512) # 像素512 512
             cam_entity.add_component(cam)
             cam_entity.name = "camera"
             self.scene.add_entity(cam_entity)
 
-        ######## Create system ########
+        ######## Create system ######## #
+        # 处理刚体或软体物理行为的IPC（Incremental Potential Contact 或 类似技术）系统
         ipc_system_config = IPCSystemConfig()
-        # memory config
+        # memory config 内存配置
         ipc_system_config.max_scenes = 1
         ipc_system_config.max_surface_primitives_per_scene = 1 << 11
         ipc_system_config.max_blocks = 1000000
-        # scene config
-        ipc_system_config.time_step = self.params.sim_time_step
-        ipc_system_config.gravity = wp.vec3(0, 0, 0)
+        # scene config 场景配置
+        ipc_system_config.time_step = self.params.sim_time_step # 仿真的时间步长 0.05
+        ipc_system_config.gravity = wp.vec3(0, 0, 0) # 重力向量
         ipc_system_config.d_hat = self.params.sim_d_hat  # 2e-4
         ipc_system_config.eps_d = self.params.sim_eps_d  # 1e-3
         ipc_system_config.eps_v = self.params.sim_eps_v  # 1e-3
         ipc_system_config.v_max = 1e-1
-        ipc_system_config.kappa = self.params.sim_kappa  # 1e3
-        ipc_system_config.kappa_affine = self.params.sim_kappa_affine
+        ipc_system_config.kappa = self.params.sim_kappa  # 1e3 1000 控制仿真稳定性的 kappa 系列参数
+        ipc_system_config.kappa_affine = self.params.sim_kappa_affine # 100000
         ipc_system_config.kappa_con = self.params.sim_kappa_con
-        ipc_system_config.ccd_slackness = self.params.ccd_slackness
-        ipc_system_config.ccd_thickness = self.params.ccd_thickness
-        ipc_system_config.ccd_tet_inversion_thres = self.params.ccd_tet_inversion_thres
-        ipc_system_config.ee_classify_thres = self.params.ee_classify_thres
-        ipc_system_config.ee_mollifier_thres = self.params.ee_mollifier_thres
-        ipc_system_config.allow_self_collision = bool(self.params.allow_self_collision)
+        ipc_system_config.ccd_slackness = self.params.ccd_slackness # 0.7# 设置连续碰撞检测（CCD）的相关参数 
+        ipc_system_config.ccd_thickness = self.params.ccd_thickness # 0.0
+        ipc_system_config.ccd_tet_inversion_thres = self.params.ccd_tet_inversion_thres # 0.0
+        ipc_system_config.ee_classify_thres = self.params.ee_classify_thres # 0.001
+        ipc_system_config.ee_mollifier_thres = self.params.ee_mollifier_thres # 0.001
+        ipc_system_config.allow_self_collision = bool(self.params.allow_self_collision) # 0.0
         # ipc_system_config.allow_self_collision = False
 
-        # solver config
+        # solver config 求解器配置
         ipc_system_config.newton_max_iters = int(self.params.sim_solver_newton_max_iters)  # key param
         ipc_system_config.cg_max_iters = int(self.params.sim_solver_cg_max_iters)
         ipc_system_config.line_search_max_iters = int(self.params.line_search_max_iters)
@@ -160,30 +169,31 @@ class LongOpenLockSimEnv(gym.Env):
         ipc_system_config.cg_error_tolerance = self.params.sim_solver_cg_error_tolerance
         ipc_system_config.cg_error_frequency = int(self.params.sim_solver_cg_error_frequency)
 
-        # set device
+        # set device 设备设置
         device = wp.get_device(device)
         ipc_system_config.device = wp.get_device(device)
 
+        # 使用前面配置的 ipc_system_config 初始化 IPCSystem，然后将这个系统添加到场景中。
         self.ipc_system = IPCSystem(ipc_system_config)
         self.scene.add_system(self.ipc_system)
 
-        self.action_space = spaces.Box(low=-1, high=1, shape=(3,), dtype=np.float32)
+        self.action_space = spaces.Box(low=-1, high=1, shape=(3,), dtype=np.float32) # low=-1 和 high=1 表示这个空间的每个维度的值都在 -1 到 1 之间。  shape=(3,) 表示这个空间是一个三维空间，即每个动作都是一个三维的向量。
         self.default_observation, _ = self.reset()
         self.observation_space = convert_observation_to_space(self.default_observation)
 
         # build scene, system
 
-    def reset(self, offset=None, seed=None, key_idx: int = None):
+    def reset(self, offset=None, seed=None):
 
         if self.viewer:
             self.viewer.close()
             self.viewer = None
-        self.params = randomize_params(self.params_lb, self.params_ub)
+        self.params = randomize_params(self.params_lb, self.params_ub) # 该函数接受两个 Params 类型的参数：lower_bound 和 upper_bound，并返回一个新的 Params 对象，其属性值在 lower_bound 和 upper_bound 之间随机选择。
         self.current_episode_elapsed_steps = 0
         self.current_episode_over = False
 
-        self.initialize(key_offset=offset, key_idx=key_idx)
-        self.init_left_surface_pts = self.no_contact_surface_mesh[0]
+        self.initialize(key_offset=offset)
+        self.init_left_surface_pts = self.no_contact_surface_mesh[0] # [52,3]
         self.init_right_surface_pts = self.no_contact_surface_mesh[1]
         self.error_evaluation_list = []
         info = self.get_info()
@@ -200,47 +210,47 @@ class LongOpenLockSimEnv(gym.Env):
         lock1_pts_center = info["lock1_pts"].mean(0) * 1000
         lock2_pts_center = info["lock2_pts"].mean(0) * 1000
 
-        error_sum += (key1_pts_center[0] - lock1_pts_center[0]) ** 2  # x direction
-        error_sum += (key2_pts_center[0] - lock2_pts_center[0]) ** 2
+        error_sum += np.abs(key1_pts_center[0] - lock1_pts_center[0])  # x direction
+        error_sum += np.abs(key2_pts_center[0] - lock2_pts_center[0])
         # print(f"reward start: {reward}")
         # z_offset
         if self.index == 0 or self.index == 2:
             if key1_pts_max[0] < 46 and key2_pts_max[0] < 46:
                 # if key is inside the lock, then encourage it to fit in to the holes
-                error_sum += (37 - key1_pts_center[2]) ** 2  # must be constrained in both directions
-                error_sum += (37 - key2_pts_center[2]) ** 2  # otherwise the policy would keep lifting the key
+                error_sum += np.abs(37 - key1_pts_center[2])  # must be constrained in both directions
+                error_sum += np.abs(37 - key2_pts_center[2])  # otherwise the policy would keep lifting the key
                 # and smooth the error to avoid sudden change
             else:
                 # else, align it with the hole
-                error_sum += (key1_pts_center[2] - 30) ** 2 + 64
-                error_sum += (key2_pts_center[2] - 30) ** 2 + 64
+                error_sum += np.abs(key1_pts_center[2] - 30) + 7
+                error_sum += np.abs(key2_pts_center[2] - 30) + 7
                 pass
         if self.index == 1:
             if key1_pts_max[0] < 52 and key2_pts_max[0] < 52:
                 # if key is inside the lock, then encourage it to fit in to the holes
-                error_sum += (37 - key1_pts_center[2]) ** 2  # must be constrained in both directions
-                error_sum += (37 - key2_pts_center[2]) ** 2  # otherwise the policy would keep lifting the key
+                error_sum += np.abs(37 - key1_pts_center[2])  # must be constrained in both directions
+                error_sum += np.abs(37 - key2_pts_center[2])  # otherwise the policy would keep lifting the key
                 # and smooth the error to avoid sudden change
             else:
                 # else, align it with the hole
-                error_sum += (key1_pts_center[2] - 30) ** 2 + 64
-                error_sum += (key2_pts_center[2] - 30) ** 2 + 64
+                error_sum += np.abs(key1_pts_center[2] - 30) + 7
+                error_sum += np.abs(key2_pts_center[2] - 30) + 7
                 pass
         if self.index == 3:
             if key1_pts_max[0] < 62 and key2_pts_max[0] < 62:
                 # if key is inside the lock, then encourage it to fit in to the holes
-                error_sum += (37 - key1_pts_center[2]) ** 2  # must be constrained in both directions
-                error_sum += (37 - key2_pts_center[2]) ** 2  # otherwise the policy would keep lifting the key
+                error_sum += np.abs(37 - key1_pts_center[2])  # must be constrained in both directions
+                error_sum += np.abs(37 - key2_pts_center[2])  # otherwise the policy would keep lifting the key
                 # and smooth the error to avoid sudden change
             else:
                 # else, align it with the hole
-                error_sum += (key1_pts_center[2] - 30) ** 2 + 64
-                error_sum += (key2_pts_center[2] - 30) ** 2 + 64
+                error_sum += np.abs(key1_pts_center[2] - 30) + 7
+                error_sum += np.abs(key2_pts_center[2] - 30) + 7
                 pass
 
         # y_offset
-        error_sum += (key1_pts_center[1]) ** 2
-        error_sum += (key2_pts_center[1]) ** 2
+        error_sum += np.abs(key1_pts_center[1])
+        error_sum += np.abs(key2_pts_center[1])
         # error_sum = np.sqrt(error_sum)
         error_sum *= error_scale
         return error_sum
@@ -250,28 +260,23 @@ class LongOpenLockSimEnv(gym.Env):
             seed = (int(time.time() * 1000) % 10000 * os.getpid()) % 2 ** 30
         np.random.seed(seed)
 
-    def initialize(self, key_offset=None, key_idx: int = None):
-
+    def initialize(self, key_offset=None):
+        
+        # 清除场景中所有非相机实体，为新的仿真周期做准备。
         for e in self.scene.entities:
             if "camera" not in e.name:
                 e.remove_from_scene()
-        self.ipc_system.rebuild()
-        print(key_idx)
-        if key_idx is None:
-            self.index = np.random.randint(len(self.key_lock_path_list))
-            key_path, lock_path = self.key_lock_path_list[np.random.randint(len(self.key_lock_path_list))]
-        else:
-            assert key_idx < len(self.key_lock_path_list)
-            self.index = key_idx
-            key_path, lock_path = self.key_lock_path_list[self.index]
+        self.ipc_system.rebuild() # 重建IPC（增量潜在接触）系统，以应对场景中实体的变化。
 
+        self.index = np.random.randint(len(self.key_lock_path_list)) # 随机选择一个锁和钥匙
+        key_path, lock_path = self.key_lock_path_list[self.index]
         asset_dir = Path(repo_path) / "assets"
         key_path = asset_dir / key_path
         lock_path = asset_dir / lock_path
 
-        if key_offset is None:
+        if key_offset is None: # 计算钥匙的位置偏移。
             if self.index == 0:
-                x_offset = np.random.rand() * self.key_x_max_offset + 46
+                x_offset = np.random.rand() * self.key_x_max_offset + 46 # 0-1随机取
             elif self.index == 1:
                 x_offset = np.random.rand() * self.key_x_max_offset + 52
             elif self.index == 2:
@@ -285,7 +290,7 @@ class LongOpenLockSimEnv(gym.Env):
             print("index=", self.index, "keyoffset=", key_offset, )
         else:
             x_offset, y_offset, z_offset = tuple(key_offset)
-            x_offset = np.clip(x_offset, 0, self.key_x_max_offset)
+            x_offset = np.clip(x_offset, 0, self.key_x_max_offset) # 限制在0-key_x_max_offset 间，用于截取数组中小于或者大于某值的部分，并使得被截取部分等于固定值。
             y_offset = np.clip(y_offset, -self.key_y_max_offset, self.key_y_max_offset)
             z_offset = np.clip(z_offset, -self.key_z_max_offset, self.key_z_max_offset)
             if self.index == 0:
@@ -301,29 +306,32 @@ class LongOpenLockSimEnv(gym.Env):
 
         key_offset = [value / 1000 for value in key_offset]
 
-        with suppress_stdout_stderr():
+#  ------------------------------导入模型------------------------------------
+        with suppress_stdout_stderr(): # 上下文管理器 抑制所有打印
             self.key_entity, key_abd = build_sapien_entity_ABD(key_path, "cuda:0", density=500.0,
-                                                               color=[1.0, 0.0, 0.0, 0.9],
-                                                               friction=self.params.key_friction,
+                                                                                color=[1.0, 0.0, 0.0, 0.9],
+                                                                                friction=self.params.key_friction,
                                                                no_render=self.no_render)
         self.key_abd = key_abd
-        self.key_entity.set_pose(sapien.Pose(p=key_offset, q=[0.7071068, 0, 0, 0]))
+        self.key_entity.set_pose(sapien.Pose(p=key_offset, q=[0.7071068, 0, 0, 0])) # p 是一个表示位置的三维向量，q 是一个表示方向的四元数。
         self.scene.add_entity(self.key_entity)
 
         with suppress_stdout_stderr():
             self.lock_entity, lock_abd = build_sapien_entity_ABD(lock_path, "cuda:0", density=500.0,
-                                                                 color=[0.0, 0.0, 1.0, 0.6],
-                                                                 friction=self.params.lock_friction,
+                                                                              color=[0.0, 0.0, 1.0, 0.6],
+                                                                              friction=self.params.lock_friction,
                                                                  no_render=self.no_render)
         self.hold_abd = lock_abd
         self.scene.add_entity(self.lock_entity)
+# ---------------------------------------------------------------------------
 
-        sensor_x = np.random.rand() * self.sensor_offset_x_range_len
+        sensor_x = np.random.rand() * self.sensor_offset_x_range_len # 2
         sensor_x = sensor_x * np.random.choice([-1, 1])
         sensor_x /= 1e3  # mm -> m
-        sensor_z = np.random.rand() * self.sensor_offset_z_range_len
+        sensor_z = np.random.rand() * self.sensor_offset_z_range_len # 2
         sensor_z = sensor_z * np.random.choice([-1, 1])
         sensor_z /= 1e3  # mm -> m
+        # 计算触觉传感器的位置和方向，基于钥匙的位置和随机生成的偏移量。
         if self.index == 0 or self.index == 2:
             init_pos_l = np.array([
                 key_offset[0] + 0.07 + sensor_x,
@@ -368,7 +376,7 @@ class LongOpenLockSimEnv(gym.Env):
                 key_offset[2] + 0.016 + sensor_z
             ])
             init_rot_r = np.array([0.7071068, 0.7071068, 0, 0])
-
+        # 触觉传感器抓握中心的初始位置。
         self.sensor_grasp_center_init = np.array([
             key_offset[0] + 0.0175 + 0.032 + sensor_x,
             key_offset[1],
@@ -384,7 +392,7 @@ class LongOpenLockSimEnv(gym.Env):
             self.viewer.set_scene(self.scene)
             self.viewer.set_camera_pose(
                 sapien.Pose([-0.0877654, 0.0921954, 0.186787], [0.846142, 0.151231, 0.32333, -0.395766]))
-            pause = True
+            pause = False
             while pause:
                 if self.viewer.window.key_down("c"):
                     pause = False
@@ -392,7 +400,7 @@ class LongOpenLockSimEnv(gym.Env):
                 ipc_update_render_all(self.scene)
                 self.viewer.render()
 
-        grasp_step = max(round((0.5 + self.params.indentation_depth) / 1000 / 2e-3 / self.params.sim_time_step), 1)
+        grasp_step = max(round((0.5 + self.params.indentation_depth) / 1000 / 2e-3 / self.params.sim_time_step), 1) # 15
         grasp_speed = (0.5 + self.params.indentation_depth) / 1000 / grasp_step / self.params.sim_time_step
 
         for grasp_step_counter in range(grasp_step):
@@ -482,7 +490,7 @@ class LongOpenLockSimEnv(gym.Env):
             "lock_side_pts": info["lock_side_pts"],
             "relative_motion": info["relative_motion"].astype(np.float32),
         }
-        obs_dict.update(extra_dict)
+        obs_dict.update(extra_dict) # 把extra_dict的内容加到obs_dict中
 
         return obs_dict
 
@@ -492,12 +500,18 @@ class LongOpenLockSimEnv(gym.Env):
         key_pts = self.key_abd.get_positions().cpu().numpy().copy()
         lock_pts = self.hold_abd.get_positions().cpu().numpy().copy()
         if self.index == 0:
-            key1_idx = np.array([16, 17, 18, 19])  # large
+            key1_idx = np.array([16, 17, 18, 19]) # large # 四个点
             key2_idx = np.array([24, 25, 26, 27])
             key_side_index = np.array([1, 3, 30, 31])
             lock1_idx = np.array([2, 3, 6, 7])
             lock2_idx = np.array([4, 5, 30, 31])
             lock_side_index = np.array([10, 11, 9, 13])
+            self.key1_pts = key_pts[key1_idx]
+            self.key2_pts = key_pts[key2_idx]
+            self.key_side_pts = key_pts[key_side_index]
+            self.lock1_pts = lock_pts[lock1_idx]
+            self.lock2_pts = lock_pts[lock2_idx]
+            self.lock_side_pts = lock_pts[lock_side_index]
         elif self.index == 1:
             key1_idx = np.array([20, 21, 22, 23])
             key2_idx = np.array([28, 29, 30, 31])
@@ -505,6 +519,12 @@ class LongOpenLockSimEnv(gym.Env):
             lock1_idx = np.array([0, 1, 6, 7])
             lock2_idx = np.array([30, 31, 2, 3])
             lock_side_index = np.array([8, 9, 11, 13])
+            self.key1_pts = key_pts[key1_idx]
+            self.key2_pts = key_pts[key2_idx]
+            self.key_side_pts = key_pts[key_side_index]
+            self.lock1_pts = lock_pts[lock1_idx]
+            self.lock2_pts = lock_pts[lock2_idx]
+            self.lock_side_pts = lock_pts[lock_side_index]
         elif self.index == 2:
             key1_idx = np.array([4, 5, 6, 7])
             key2_idx = np.array([12, 13, 14, 15])
@@ -512,6 +532,12 @@ class LongOpenLockSimEnv(gym.Env):
             lock1_idx = np.array([6, 7, 2, 3])
             lock2_idx = np.array([4, 5, 30, 31])
             lock_side_index = np.array([10, 9, 11, 13])
+            self.key1_pts = key_pts[key1_idx]
+            self.key2_pts = key_pts[key2_idx]
+            self.key_side_pts = key_pts[key_side_index]
+            self.lock1_pts = lock_pts[lock1_idx]
+            self.lock2_pts = lock_pts[lock2_idx]
+            self.lock_side_pts = lock_pts[lock_side_index]
         elif self.index == 3:
             key1_idx = np.array([8, 9, 10, 11])
             key2_idx = np.array([16, 17, 18, 19])
@@ -519,14 +545,19 @@ class LongOpenLockSimEnv(gym.Env):
             lock1_idx = np.array([2, 3, 10, 11])
             lock2_idx = np.array([6, 7, 8, 9])
             lock_side_index = np.array([12, 13, 15, 17])
-
-        self.key1_pts = key1_pts = key_pts[key1_idx]
-        self.key2_pts = key2_pts = key_pts[key2_idx]
-        self.key_side_pts = key_side_pts = key_pts[key_side_index]
-        self.lock1_pts = lock1_pts = lock_pts[lock1_idx]
-        self.lock2_pts = lock2_pts = lock_pts[lock2_idx]
-        self.lock_side_pts = lock_side_pts = lock_pts[lock_side_index]
-
+            self.key1_pts = key_pts[key1_idx]
+            self.key2_pts = key_pts[key2_idx]
+            self.key_side_pts = key_pts[key_side_index]
+            self.lock1_pts = lock_pts[lock1_idx]
+            self.lock2_pts = lock_pts[lock2_idx]
+            self.lock_side_pts = lock_pts[lock_side_index]
+
+        key1_pts = self.key1_pts
+        key2_pts = self.key2_pts
+        key_side_pts = self.key_side_pts
+        lock1_pts = self.lock1_pts
+        lock2_pts = self.lock2_pts
+        lock_side_pts = self.lock_side_pts
         info["key1_pts"] = key1_pts
         info["key2_pts"] = key2_pts
         info["key_side_pts"] = key_side_pts
@@ -534,7 +565,7 @@ class LongOpenLockSimEnv(gym.Env):
         info["lock2_pts"] = lock2_pts
         info["lock_side_pts"] = lock_side_pts
 
-        observation_left_surface_pts, observation_right_surface_pts = self._get_sensor_surface_vertices()
+        observation_left_surface_pts, observation_right_surface_pts = self._get_sensor_surface_vertices() # 获取触觉传感器的表面顶点。 [52,3] [52,3]
         l_diff = np.mean(
             np.sqrt(
                 np.sum((self.init_left_surface_pts - observation_left_surface_pts) ** 2, axis=-1)
@@ -549,8 +580,12 @@ class LongOpenLockSimEnv(gym.Env):
         info["tactile_movement_too_large"] = False
         if l_diff > 1.5e-3 or r_diff > 1.5e-3:
             info["tactile_movement_too_large"] = True
-        info["relative_motion"] = 1e3 * (self.sensor_grasp_center_current - self.sensor_grasp_center_init)
+        info["relative_motion"] = 1e3 * (self.sensor_grasp_center_current - self.sensor_grasp_center_init) # 乘以1000，将单位从米转换为毫米。 传感器抓握中心的相对运动。
         info["error_too_large"] = False
+    #     array([[ 0.0709715 , -0.00302903,  0.02911181],
+    #    [ 0.07097052,  0.00296741,  0.02912232],
+    #    [ 0.06497135, -0.00303   ,  0.02910838],
+    #    [ 0.06497037,  0.00296644,  0.02911888]], dtype=float32)
         if np.abs(info["key1_pts"].mean(0)[1]) > 0.01 or np.abs(info["key2_pts"].mean(0)[1]) > 0.01 or \
                 info["key1_pts"].mean(0)[2] > 0.045 or info["key2_pts"].mean(0)[2] > 0.045 or \
                 info["key1_pts"].mean(0)[2] < 0.015 or info["key2_pts"].mean(0)[2] < 0.015 or \
@@ -558,6 +593,7 @@ class LongOpenLockSimEnv(gym.Env):
             info["error_too_large"] = True
 
         info["is_success"] = False
+        # key1_pts [4,3] key1_pts[:, 0] [4,] key1_pts[:, 0].max() 0.110 key1_pts[:, 0].min() 0.06497037
         if key1_pts[:, 0].max() < info["lock_side_pts"].mean(0)[0] and key1_pts[:, 0].min() > 0 and \
                 key2_pts[:, 0].max() < info["lock_side_pts"].mean(0)[0] and key2_pts[:, 0].min() > 0 and \
                 np.abs(key1_pts[:, 1].mean()) < 0.002 and np.abs(key2_pts[:, 1].mean()) < 0.002 and \
@@ -567,15 +603,15 @@ class LongOpenLockSimEnv(gym.Env):
         return info
 
     def get_reward(self, info):
-        self.error_evaluation_list.append(self.evaluate_error(info))
-        reward = -self.step_penalty
+        self.error_evaluation_list.append(self.evaluate_error(info)) #369.50026904046535
+        reward = -self.step_penalty # 1
         # x_offset
-        reward += self.error_evaluation_list[-2] - self.error_evaluation_list[-1]
+        reward += self.error_evaluation_list[-2] - self.error_evaluation_list[-1] #  6.694728814065456 最后一个reward减去倒数第二个reward
 
         # print(f"reward part3: {reward}")
         # punish large force
-        surface_diff = info["surface_diff"].clip(0.2e-3, 1.5e-3) * 1000
-        reward -= np.sum(10 / (1.55 - surface_diff)) - 15  # max is 200 + 200 = 400
+        surface_diff = info["surface_diff"].clip(0.2e-3, 1.5e-3) * 1000 # array([0.2, 0.2])
+        reward -= np.sum(10 / (1.55 - surface_diff)) - 15  # max is 200 + 200 = 400 -0.1851851851851869
         # print(f"reward part4: {reward}")
 
         if info["is_success"]:
@@ -622,11 +658,10 @@ class LongOpenLockSimEnv(gym.Env):
         self.ipc_system = None
         pass
 
-
 class LongOpenLockRandPointFlowEnv(LongOpenLockSimEnv):
     def __init__(
             self,
-            render_rgb: bool = False,
+            render_rgb: bool = True,
             marker_interval_range: Tuple[float, float] = (2., 2.),
             marker_rotation_range: float = 0.,
             marker_translation_range: Tuple[float, float] = (0., 0.),
@@ -710,8 +745,8 @@ class LongOpenLockRandPointFlowEnv(LongOpenLockSimEnv):
 
     def get_obs(self, info=None):
         obs = super().get_obs(info=info)
-        obs.pop("surface_pts")
-        obs["marker_flow"] = np.stack(
+        obs.pop("surface_pts") # 删除surface_pts
+        obs["marker_flow"] = np.stack( # 增加marker_flow
             [
                 self.tactile_sensor_1.gen_marker_flow(),
                 self.tactile_sensor_2.gen_marker_flow(),
@@ -719,15 +754,14 @@ class LongOpenLockRandPointFlowEnv(LongOpenLockSimEnv):
             axis=0
         ).astype(np.float32)
 
-        key1_pts = obs.pop("key1_pts")
+        key1_pts = obs.pop("key1_pts") # （4，3）
         key2_pts = obs.pop("key2_pts")
         # key_end_pts = obs.pop("key_end_pts")
-        obs["key1"] = np.array(
-            [key1_pts.mean(0)[0] - info["lock1_pts"].mean(0)[0], key1_pts.mean(0)[1], key1_pts.mean(0)[2] - 0.03],
-            dtype=np.float32) * 200.0
-        obs["key2"] = np.array(
-            [key2_pts.mean(0)[0] - info["lock2_pts"].mean(0)[0], key2_pts.mean(0)[1], key2_pts.mean(0)[2] - 0.03],
-            dtype=np.float32) * 200.0
+        # key1_pts.mean(0) 每一列（四个点）求均值[0.0709715 , -0.00302903,  0.02911181]
+        obs["key1"] = np.array([key1_pts.mean(0)[0] - info["lock1_pts"].mean(0)[0], key1_pts.mean(0)[1], key1_pts.mean(0)[2] - 0.03], # 高度0.3固定
+                               dtype=np.float32) * 200.0
+        obs["key2"] = np.array([key2_pts.mean(0)[0] - info["lock2_pts"].mean(0)[0], key2_pts.mean(0)[1], key2_pts.mean(0)[2] - 0.03],
+                               dtype=np.float32) * 200.0
 
         if self.render_rgb:
             obs["rgb_images"] = np.stack(
@@ -747,8 +781,8 @@ if __name__ == "__main__":
         if not os.path.exists(save_dir):
             os.makedirs(save_dir)
 
-        lr_marker_flow = o["marker_flow"]
-        l_marker_flow, r_marker_flow = lr_marker_flow[0], lr_marker_flow[1]
+        lr_marker_flow = o["marker_flow"] # 'marker_flow_images_4'
+        l_marker_flow, r_marker_flow = lr_marker_flow[0], lr_marker_flow[1] # (2, 128, 2)
         plt.figure(1, (20, 9))
         ax = plt.subplot(1, 2, 1)
         ax.scatter(l_marker_flow[0, :, 0], l_marker_flow[0, :, 1], c="blue")
@@ -766,8 +800,21 @@ if __name__ == "__main__":
         # Save the figure with a filename based on the loop parameter i
         filename = os.path.join(save_dir, f"sp-from-sapien-{name}-marker_flow_{i}.png")
         plt.savefig(filename)
+        # plt.show(block=False)
+        plt.show()
+        plt.pause(1)	
         plt.close()
 
+    def visualize_depth(o):
+        lr_depth = o["rgb_images"]
+        l_depth, r_depth = lr_depth[0], lr_depth[1]
+        cv2.namedWindow("l_depth")     # 创建一个image的窗口
+        cv2.imshow("l_depth", l_depth)    # 显示图像
+        cv2.namedWindow("r_depth")     # 创建一个image的窗口
+        cv2.imshow("r_depth", r_depth)    # 显示图像 
+        cv2.waitKey(1000)               # 默认为0，无限等待
+        
+
 
     GUI = True
     timestep = 0.05
@@ -781,6 +828,39 @@ if __name__ == "__main__":
         elastic_modulus_l=3e5,
     )
     print(params)
+#     -----------Parameters-----------------
+#           allow_self_collision: 0                                                           
+#                  ccd_max_iters: 10                                                          
+#                  ccd_slackness: 0.7                                                         
+#        ccd_tet_inversion_thres: 0.0                                                         
+#                  ccd_thickness: 0.0                                                         
+#              ee_classify_thres: 0.001                                                       
+#             ee_mollifier_thres: 0.001                                                       
+#              indentation_depth: 1.0                                                         
+#                   key_friction: 1.0                                                         
+#             key_lock_path_file: configs/key_and_lock/key_lock.txt                           
+#          line_search_max_iters: 10                                                          
+#                  lock_friction: 1.0                                                         
+#                      sim_d_hat: 0.0002                                                      
+#                      sim_eps_d: 0.0001                                                      
+#                      sim_eps_v: 0.001                                                       
+#                      sim_kappa: 1000.0                                                      
+#               sim_kappa_affine: 100000.0                                                    
+#                  sim_kappa_con: 10000000000.0                                               
+#  sim_solver_cg_error_frequency: 10                                                          
+#  sim_solver_cg_error_tolerance: 0.0001                                                      
+#        sim_solver_cg_max_iters: 50                                                          
+#    sim_solver_newton_max_iters: 4                                                           
+#                  sim_time_step: 0.05                                                        
+#                  tac_density_l: 1000                                                        
+#                  tac_density_r: 1000                                                        
+#          tac_elastic_modulus_l: 1000000.0                                                   
+#          tac_elastic_modulus_r: 1000000.0                                                   
+#                   tac_friction: 1.0                                                         
+#            tac_poisson_ratio_l: 0.3                                                         
+#            tac_poisson_ratio_r: 0.3                                                         
+#           tac_sensor_meta_file: gelsight_mini_e430/meta_file                                
+# -----------------------End-----------------------
 
     env = LongOpenLockRandPointFlowEnv(
         params=params,
@@ -814,6 +894,7 @@ if __name__ == "__main__":
     for i in range(25):
         obs, rew, done, _, info = env.step(np.array([0.5, 0.0, 0.0]))
         visualize_marker_point_flow(obs, i, "test")
+        visualize_depth(obs)
         print(
             f"step: {env.current_episode_elapsed_steps:2d} rew: {rew:.2f} done: {done} success: {info['is_success']}"
         )
@@ -821,6 +902,7 @@ if __name__ == "__main__":
     for i in range(4):
         obs, rew, done, _, info = env.step(np.array([0.0, 0.0, -0.5]))
         visualize_marker_point_flow(obs, i + 24, "test")
+        visualize_depth(obs)
         print(
             f"step: {env.current_episode_elapsed_steps:2d} rew: {rew:.2f} done: {done} success: {info['is_success']}"
         )
@@ -828,6 +910,7 @@ if __name__ == "__main__":
     for i in range(10):
         obs, rew, done, _, info = env.step(np.array([0.5, 0.0, 0.0]))
         visualize_marker_point_flow(obs, i + 28, "test")
+        visualize_depth(obs)
         print(
             f"step: {env.current_episode_elapsed_steps:2d} rew: {rew:.2f} done: {done} success: {info['is_success']}"
         )
@@ -835,6 +918,8 @@ if __name__ == "__main__":
     for i in range(8):
         obs, rew, done, _, info = env.step(np.array([0.0, 0.0, -0.5]))
         visualize_marker_point_flow(obs, i + 38, "test")
+        visualize_depth(obs)
         print(
             f"step: {env.current_episode_elapsed_steps:2d} rew: {rew:.2f} done: {done} success: {info['is_success']}"
         )
+    cv2.destroyAllWindows() 
\ No newline at end of file
diff --git a/envs/peg_insertion.py b/envs/peg_insertion.py
old mode 100644
new mode 100755
index 260fa7b..d86ebfe
--- a/envs/peg_insertion.py
+++ b/envs/peg_insertion.py
@@ -46,6 +46,12 @@ def evaluate_error(offset):
     error = math.sqrt(offset_squared[0] + offset_squared[1] + offset_squared[2])
     return error
 
+def evaluate_error_custom(offset):
+    offset_abs = np.abs(offset)
+    offset_filtered = np.where(offset_abs < 0.1, 0.1, offset_abs)
+    offset_reciprocal = np.reciprocal(offset_filtered)
+    error = np.sum(offset_reciprocal)/3
+    return error
 
 class ContinuousInsertionParams(CommonParams):
     def __init__(self,
@@ -482,6 +488,8 @@ class ContinuousInsertionSimEnv(gym.Env):
         self.current_offset_of_current_episode = offset
         self.error_evaluation_list = []
         self.error_evaluation_list.append(evaluate_error(self.current_offset_of_current_episode))
+        self.error_evaluation_list_2 = []
+        self.error_evaluation_list_2.append(evaluate_error_custom(self.current_offset_of_current_episode))
         self.current_episode_initial_left_surface_pts = self.no_contact_surface_mesh[0]
         self.current_episode_initial_right_surface_pts = self.no_contact_surface_mesh[1]
         self.current_episode_over = False
@@ -626,7 +634,8 @@ class ContinuousInsertionSimEnv(gym.Env):
 
         info = self.get_info()
         obs = self.get_obs(info=info)
-        reward = self.get_reward(info=info, obs=obs)
+        # reward = self.get_reward(info=info, obs=obs)
+        reward = self.get_reward_custom(info=info, obs=obs)
         terminated = self.get_terminated(info=info, obs=obs)
         truncated = self.get_truncated(info=info, obs=obs)
         return obs, reward, terminated, truncated, info
@@ -712,6 +721,21 @@ class ContinuousInsertionSimEnv(gym.Env):
             reward += self.final_reward
 
         return reward
+    
+    def get_reward_custom(self, info, obs=None):
+        self.error_evaluation_list.append(evaluate_error(self.current_offset_of_current_episode))
+        # reward = self.error_evaluation_list[-2] - self.error_evaluation_list[-1] - self.step_penalty
+        self.error_evaluation_list_2.append(evaluate_error_custom(self.current_offset_of_current_episode))
+        reward = self.error_evaluation_list[-2] - self.error_evaluation_list[-1] + self.error_evaluation_list_2[-1] - self.error_evaluation_list_2[-2] - self.step_penalty
+            
+        if info["too_many_steps"]:
+            reward = 0
+        elif info["error_too_large"]:
+            reward += -2 * self.step_penalty * (self.max_steps - self.current_episode_elapsed_steps) + self.step_penalty
+        elif info["is_success"]:
+            reward += self.final_reward
+
+        return reward
 
     def get_truncated(self, info, obs=None):
         return info["steps"] >= self.max_steps
@@ -951,7 +975,6 @@ if __name__ == "__main__":
         plt.savefig(filename)
         plt.close()
 
-
     offset_list = [[4, 0, 0], [-4, 0, 0], [0, 4, 0], [0, -4, 0]]
     for offset in offset_list:
         o, _ = env.reset(offset)
diff --git a/envs/phong_shading.py b/envs/phong_shading.py
old mode 100644
new mode 100755
diff --git a/envs/render_config.yml b/envs/render_config.yml
old mode 100644
new mode 100755
diff --git a/envs/tactile_sensor_sapienipc.py b/envs/tactile_sensor_sapienipc.py
old mode 100644
new mode 100755
diff --git a/pretrain_weight/pretrain_openlock/best_model.zip b/pretrain_weight/pretrain_openlock/best_model.zip
old mode 100644
new mode 100755
diff --git a/pretrain_weight/pretrain_peg_insertion/best_model.zip b/pretrain_weight/pretrain_peg_insertion/best_model.zip
old mode 100644
new mode 100755
diff --git a/real_env_demo/continuous_insertion_real.py b/real_env_demo/continuous_insertion_real.py
old mode 100644
new mode 100755
diff --git a/real_env_demo/evaluation_script_for_peg_in_hole.py b/real_env_demo/evaluation_script_for_peg_in_hole.py
old mode 100644
new mode 100755
diff --git a/scripts/__init__.py b/scripts/__init__.py
old mode 100644
new mode 100755
diff --git a/scripts/arguments.py b/scripts/arguments.py
old mode 100644
new mode 100755
diff --git a/scripts/open_lock_sim_evaluation.py b/scripts/open_lock_sim_evaluation.py
old mode 100644
new mode 100755
index b1384ca..3e15a25
--- a/scripts/open_lock_sim_evaluation.py
+++ b/scripts/open_lock_sim_evaluation.py
@@ -2,6 +2,11 @@ import copy
 import os
 import sys
 import time
+from path import Path
+script_path = os.path.dirname(os.path.realpath(__file__))
+repo_path = os.path.join(script_path, "..")
+sys.path.append(script_path)
+sys.path.insert(0, repo_path)
 import numpy as np
 import ruamel.yaml as yaml
 import torch
@@ -9,22 +14,15 @@ from stable_baselines3.common.save_util import load_from_zip_file
 
 from scripts.arguments import parse_params
 from envs.long_open_lock import LongOpenLockRandPointFlowEnv
-from path import Path
+
 from stable_baselines3.common.utils import set_random_seed
 
 from solutions.policies import TD3PolicyForLongOpenLockPointFlowEnv
 from utils.common import get_time, get_average_params
 from loguru import logger
 
-script_path = os.path.dirname(os.path.realpath(__file__))
-repo_path = os.path.join(script_path, "..")
-sys.path.append(script_path)
-sys.path.insert(0, repo_path)
 
-script_path = os.path.dirname(os.path.realpath(__file__))
-repo_path = os.path.join(script_path, "..")
-sys.path.append(script_path)
-sys.path.insert(0, repo_path)
+
 
 EVAL_CFG_FILE = os.path.join(repo_path, "configs/evaluation/open_lock_evaluation.yaml")
 KEY_NUM = 4
@@ -121,7 +119,7 @@ if __name__ == "__main__":
     key = args.key
     # replace the model with your own policy
 
-    policy_file = "../pretrain_weight/pretrain_openlock/best_model.zip"
+    policy_file = "./pretrain_weight/pretrain_openlock/best_model"
     data, params, _ = load_from_zip_file(policy_file)
     model = TD3PolicyForLongOpenLockPointFlowEnv(observation_space=data["observation_space"],
                                     action_space=data["action_space"],
diff --git a/scripts/peg_insertion_sim_evaluation.py b/scripts/peg_insertion_sim_evaluation.py
old mode 100644
new mode 100755
index e755c12..92af068
--- a/scripts/peg_insertion_sim_evaluation.py
+++ b/scripts/peg_insertion_sim_evaluation.py
@@ -6,7 +6,10 @@ import numpy as np
 import ruamel.yaml as yaml
 import torch
 from stable_baselines3.common.save_util import load_from_zip_file
-
+script_path = os.path.dirname(os.path.realpath(__file__))
+repo_path = os.path.join(script_path, "..")
+sys.path.append(script_path)
+sys.path.insert(0, repo_path)
 from scripts.arguments import parse_params, handle_policy_args
 from envs.peg_insertion import ContinuousInsertionSimGymRandomizedPointFLowEnv
 from path import Path
@@ -17,10 +20,7 @@ from loguru import logger
 from scripts.arguments import parse_params
 from solutions.policies import TD3PolicyForPointFlowEnv
 
-script_path = os.path.dirname(os.path.realpath(__file__))
-repo_path = os.path.join(script_path, "..")
-sys.path.append(script_path)
-sys.path.insert(0, repo_path)
+
 
 EVAL_CFG_FILE = os.path.join(repo_path, "configs/evaluation/peg_insertion_evaluation.yaml")
 PEG_NUM = 3
@@ -120,12 +120,13 @@ if __name__ == "__main__":
     import argparse
 
     parser = argparse.ArgumentParser()
-    parser.add_argument("--key", type=str, required=True, help="use the key sent to you")
+    # parser.add_argument("--key", type=str, required=True, help="use the key sent to you")
+    parser.add_argument("--key", type=str, required=False, help="use the key sent to you")
     parser.add_argument("--render_rgb",action="store_true")
     args = parser.parse_args()
     key = args.key
-
-    policy_file = "../pretrain_weight/pretrain_peg_insertion/best_model.zip"
+    key=1
+    policy_file = "./pretrain_weight/pretrain_peg_insertion/best_model"
     data, params, _ = load_from_zip_file(policy_file)
     model = TD3PolicyForPointFlowEnv(observation_space=data["observation_space"],
                                     action_space=data["action_space"],
diff --git a/scripts/universal_training_script.py b/scripts/universal_training_script.py
old mode 100644
new mode 100755
index 1738c03..86b577b
--- a/scripts/universal_training_script.py
+++ b/scripts/universal_training_script.py
@@ -14,6 +14,7 @@ from path import Path
 from solutions.policies import (
     TD3PolicyForPointFlowEnv, TD3PolicyForLongOpenLockPointFlowEnv
 )
+
 from stable_baselines3 import TD3
 from stable_baselines3.common.callbacks import (CallbackList,
                                                 CheckpointCallback,
@@ -24,6 +25,7 @@ from utils.common import get_time
 from wandb.integration.sb3 import WandbCallback
 
 import wandb
+
 from arguments import *
 
 algorithm_aliases = {
@@ -51,6 +53,8 @@ def make_env(env_name, seed=0, i=0, **env_args):
 if __name__ == "__main__":
     parser = get_parser()
     args = parser.parse_args()
+    # args.cfg='configs/parameters/peg_insertion.yaml'
+    args.cfg='configs/parameters/long_open_lock.yaml'
     with open(args.cfg, "r") as f:
         cfg = yaml.YAML(typ='safe', pure=True).load(f)
 
@@ -146,12 +150,11 @@ if __name__ == "__main__":
         n_eval_episodes=cfg["train"]["n_eval"],
     )
 
-    WANDB = False
+    WANDB = True
     if WANDB:
         wandb_run = wandb.init(
             project=cfg["train"]["wandb_name"],
             name=f"{cfg['train']['name']}_{exp_start_time}",
-            entity="openlock",
             config=cfg,
             sync_tensorboard=True,
             monitor_gym=False,
diff --git a/solutions/__init__.py b/solutions/__init__.py
old mode 100644
new mode 100755
diff --git a/solutions/actor_and_critics.py b/solutions/actor_and_critics.py
old mode 100644
new mode 100755
index 6445222..d00d423
--- a/solutions/actor_and_critics.py
+++ b/solutions/actor_and_critics.py
@@ -79,9 +79,9 @@ class PointNetActor(Actor):
         l_point_flow_fea = point_flow_fea[:batch_num, ...]
         r_point_flow_fea = point_flow_fea[batch_num:, ...]
 
-        point_flow_fea = torch.cat([l_point_flow_fea, r_point_flow_fea], dim=-1)
+        point_flow_fea = torch.cat([l_point_flow_fea, r_point_flow_fea], dim=-1) # [2*64]
 
-        pred = self.mlp_policy(point_flow_fea)
+        pred = self.mlp_policy(point_flow_fea) # [2*3]
 
         return pred
 
diff --git a/solutions/custom_pointnet_autoencoder_policy.py b/solutions/custom_pointnet_autoencoder_policy.py
old mode 100644
new mode 100755
diff --git a/solutions/feature_extractors.py b/solutions/feature_extractors.py
old mode 100644
new mode 100755
diff --git a/solutions/networks.py b/solutions/networks.py
old mode 100644
new mode 100755
index 8e6f27e..5c9ace3
--- a/solutions/networks.py
+++ b/solutions/networks.py
@@ -4,6 +4,19 @@ import torch
 import torch.nn.functional as F
 from torch import nn
 
+def latent_pi_net_custom(mlp_in_channels):
+    layernorm = False
+    out_dim = 256
+    latent_pi_net=[nn.Linear(mlp_in_channels, 256),
+            nn.LayerNorm(256) if layernorm else nn.Identity(),
+            nn.ReLU(),
+            nn.Linear(256, 256),
+            nn.LayerNorm(256) if layernorm else nn.Identity(),
+            nn.ReLU(),
+            nn.Linear(256, out_dim),
+            nn.Tanh()]
+    return latent_pi_net, out_dim
+
 
 class PointNetFea(nn.Module):
     def __init__(self, point_dim, output_dim, batchnorm=False):
@@ -39,11 +52,11 @@ class PointNetFea(nn.Module):
         return x
 
 
-class PointNetFeaNew(nn.Module):
+class PointNetFeaNew(nn.Module): # 64->128->512
     def __init__(self, point_dim, net_layers: List, batchnorm=False):
         super(PointNetFeaNew, self).__init__()
-        self.layer_num = len(net_layers)
-        self.conv0 = nn.Conv1d(point_dim, net_layers[0], 1)
+        self.layer_num = len(net_layers) # net_layers=[64, 128, 512]
+        self.conv0 = nn.Conv1d(point_dim, net_layers[0], 1) # point_dim=64
         self.bn0 = nn.BatchNorm1d(net_layers[0]) if batchnorm else nn.Identity()
         for i in range(0, self.layer_num - 1):
             self.__setattr__(f"conv{i + 1}", nn.Conv1d(net_layers[i], net_layers[i + 1], 1))
@@ -71,15 +84,15 @@ class PointNetFeatureExtractor(nn.Module):
     need to distinguish this from other modules defined in feature_extractors.py
     those modules are only used to extract the corresponding input (e.g. point flow, manual feature, etc.) from original observations
     """
-    def __init__(self, dim, out_dim, batchnorm=False):
+    def __init__(self, dim, out_dim, batchnorm=False): # out_dim=32
         super(PointNetFeatureExtractor, self).__init__()
-        self.dim = dim
+        self.dim = dim # 4
 
         self.pointnet_local_feature_num = 64
         self.pointnet_global_feature_num = 512
         # self.mlp_feature_num = 256  # self.pointnet_global_feature_num  #256
 
-        self.pointnet_local_fea = nn.Sequential(
+        self.pointnet_local_fea = nn.Sequential( # 4->64->64->64
             nn.Conv1d(dim, self.pointnet_local_feature_num, 1),
             nn.BatchNorm1d(self.pointnet_local_feature_num) if batchnorm else nn.Identity(),
             nn.ReLU(),
@@ -87,7 +100,7 @@ class PointNetFeatureExtractor(nn.Module):
             nn.BatchNorm1d(self.pointnet_local_feature_num) if batchnorm else nn.Identity(),
             nn.ReLU(),
         )
-        self.pointnet_global_fea = PointNetFeaNew(self.pointnet_local_feature_num, [64, 128, self.pointnet_global_feature_num], batchnorm=batchnorm)
+        self.pointnet_global_fea = PointNetFeaNew(self.pointnet_local_feature_num, [64, 128, self.pointnet_global_feature_num], batchnorm=batchnorm) # 64->128->512
         # self.pointnet_total_fea = PointNetFeaNew(
         #     self.pointnet_local_feature_num + self.pointnet_global_feature_num, [512, self.mlp_feature_num], batchnorm=batchnorm
         # )
@@ -101,18 +114,18 @@ class PointNetFeatureExtractor(nn.Module):
         :param marker_pos: Tensor, size (batch, num_points, 4)
         :return:
         """
-        if marker_pos.ndim == 2:
+        if marker_pos.ndim == 2: # marker_pos：torch.Size([128, 128, 4])
             marker_pos = torch.unsqueeze(marker_pos, dim=0)
 
-        marker_pos = torch.transpose(marker_pos, 1, 2)
+        marker_pos = torch.transpose(marker_pos, 1, 2) # torch.Size([128, 4, 128]) 特征维放到第二个位置
 
-        batch_num = marker_pos.shape[0]
-        point_num = marker_pos.shape[2]
+        # batch_num = marker_pos.shape[0] # 128
+        # point_num = marker_pos.shape[2] # 128
 
-        local_feature = self.pointnet_local_fea(marker_pos)  # (batch_num, self.pointnet_local_feature_num, point_num)
+        local_feature = self.pointnet_local_fea(marker_pos)  # (batch_num, self.pointnet_local_feature_num, point_num) torch.Size([128, 64, 128])
         # shape: (batch, step * 2, num_points)
         global_feature = self.pointnet_global_fea(local_feature).view(
-            -1, self.pointnet_global_feature_num)  # (batch_num, self.pointnet_global_feature_num)
+            -1, self.pointnet_global_feature_num)  # (batch_num, self.pointnet_global_feature_num) # torch.Size([128, 512])
 
         # global_feature = global_feature.repeat(
         #     (1, 1, point_num)
diff --git a/solutions/policies.py b/solutions/policies.py
old mode 100644
new mode 100755
diff --git a/utils/__init__.py b/utils/__init__.py
old mode 100644
new mode 100755
diff --git a/utils/collect_env.py b/utils/collect_env.py
old mode 100644
new mode 100755
diff --git a/utils/common.py b/utils/common.py
old mode 100644
new mode 100755
diff --git a/utils/geometry.py b/utils/geometry.py
old mode 100644
new mode 100755
diff --git a/utils/gym_env_utils.py b/utils/gym_env_utils.py
old mode 100644
new mode 100755
diff --git a/utils/sapienipc_utils.py b/utils/sapienipc_utils.py
old mode 100644
new mode 100755
