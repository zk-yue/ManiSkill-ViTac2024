wandb_version: 1

env:
  desc: null
  value:
    step_penalty: 1
    final_reward: 10
    max_action:
    - 2.0
    - 2.0
    - 4.0
    max_steps: 100
    z_step_size: 0.125
    peg_hole_path_file: configs/peg_insertion/3shape_2.0mm.txt
    peg_x_max_offset: 5.0
    peg_y_max_offset: 5.0
    peg_theta_max_offset: 10.0
    marker_interval_range:
    - 1.95
    - 2.15
    marker_rotation_range: 0.1
    marker_translation_range:
    - 1
    - 1
    marker_pos_shift_range:
    - 0.1
    - 0.1
    marker_random_noise: 0.5
    marker_lose_tracking_probability: 0.01
    normalize: false
policy:
  desc: null
  value:
    buffer_size: 200000
    train_freq: 2
    gradient_steps: -1
    learning_starts: 2000
    action_noise: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5
      0.5])), n_envs=10)
    batch_size: 256
    learning_rate: 0.0001
    optimize_memory_usage: false
    ent_coef: auto
    target_update_interval: 1
    target_entropy: auto
    use_sde: false
    sde_sample_freq: -1
    use_sde_at_warmup: false
    policy_kwargs:
      pointnet_in_dim: 4
      pointnet_out_dim: 32
      pointnet_batchnorm: false
      pointnet_layernorm: true
      zero_init_output: true
      use_sde: false
    device: cuda:0
    seed: 0
    tensorboard_log: /media/lab/data/yzk/ManiSkill-ViTac2024/scripts/../training_log/3shape_2.0mm_2024-03-17_20-02-44.394
train:
  desc: null
  value:
    total_timesteps: 500000
    log_interval: 10
    checkpoint_every: 2000
    eval_freq: 2000
    n_eval: 50
    parallel: 10
    seed: 0
    device: cuda:0
    gpu: 0
    name: 3shape_2.0mm
    wandb_name: ManiSkill_ViTac
    emp: {}
cfg:
  desc: null
  value: configs/parameters/peg_insertion_sac.yaml
no_render:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    code_path: code/scripts/train_sac.py
    python_version: 3.10.0
    cli_version: 0.16.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1710676970.262507
    t:
      1:
      - 1
      - 5
      - 53
      - 55
      2:
      - 1
      - 5
      - 53
      - 55
      3:
      - 13
      - 16
      - 22
      - 23
      - 35
      4: 3.10.0
      5: 0.16.0
      8:
      - 5
      13: linux-x86_64
algo:
  desc: null
  value: SAC
policy_class:
  desc: null
  value: <class 'solutions.policies_sac.SACPolicyForPointFlowEnv'>
device:
  desc: null
  value: cuda:0
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{''pointnet_in_dim'': 4, ''pointnet_out_dim'': 32, ''pointnet_batchnorm'':
    False, ''pointnet_layernorm'': True, ''zero_init_output'': True, ''use_sde'':
    False}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 500000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: 0
action_noise:
  desc: null
  value: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5 0.5])), n_envs=10)
start_time:
  desc: null
  value: 1710676974778799111
learning_rate:
  desc: null
  value: 0.0001
tensorboard_log:
  desc: null
  value: /media/lab/data/yzk/ManiSkill-ViTac2024/scripts/../training_log/3shape_2.0mm_2024-03-17_20-02-44.394
_last_obs:
  desc: null
  value: "OrderedDict([('gt_offset', array([[-4.6071973 ,  0.07924887, -7.781707 \
    \ ],\n       [-4.771731  ,  0.47126797,  8.176322  ],\n       [-2.3347828 ,  3.7303922\
    \ , -7.9120364 ],\n       [ 4.3850303 , -3.7589793 , -9.249313  ],\n       [ 2.4540803\
    \ ,  1.9136795 ,  2.174851  ],\n       [ 3.0047102 ,  4.9259496 , -9.320199  ],\n\
    \       [ 4.102955  , -3.7628136 ,  6.792545  ],\n       [-4.462641  ,  3.291415\
    \  , -1.8084762 ],\n       [ 1.9195799 ,  0.38389036, -4.3854117 ],\n       [-3.107409\
    \  ,  3.7989318 ,  9.6160345 ]], dtype=float32)), ('marker_flow', array([[[[[\
    \ 23.931177 ,  14.213257 ],\n          [ 59.47037  ,  15.817823 ],\n         \
    \ [ 93.334526 ,  16.334988 ],\n          ...,\n          [294.80188  , 224.49928\
    \  ],\n          [294.80188  , 224.49928  ],\n          [294.80188  , 224.49928\
    \  ]],\n\n         [[ 27.090084 ,  14.416104 ],\n          [ 62.769615 ,  15.4347315],\n\
    \          [ 96.33387  ,  16.39933  ],\n          ...,\n          [298.10107 \
    \ , 223.76344  ],\n          [298.10107  , 223.76344  ],\n          [298.10107\
    \  , 223.76344  ]]],\n\n\n        [[[  5.9616737,  39.244522 ],\n          [ 39.245605\
    \ ,  37.255062 ],\n          [ 71.02473  ,  33.898445 ],\n          ...,\n   \
    \       [285.8605   , 232.7646   ],\n          [285.8605   , 232.7646   ],\n \
    \         [285.8605   , 232.7646   ]],\n\n         [[  8.942158 ,  39.53945  ],\n\
    \          [ 41.03727  ,  37.01846  ],\n          [ 73.307945 ,  32.380188 ],\n\
    \          ...,\n          [289.80997  , 233.1343   ],\n          [289.80997 \
    \ , 233.1343   ],\n          [289.80997  , 233.1343   ]]]],\n\n\n\n       [[[[\
    \ 32.14803  ,  36.73216  ],\n          [ 63.13524  ,  37.436005 ],\n         \
    \ [ 93.07313  ,  35.697235 ],\n          ...,\n          [284.55197  , 216.04897\
    \  ],\n          [284.55197  , 216.04897  ],\n          [284.55197  , 216.04897\
    \  ]],\n\n         [[ 34.896328 ,  37.406807 ],\n          [ 66.041626 ,  37.730576\
    \ ],\n          [ 95.28693  ,  34.16033  ],\n          ...,\n          [289.25125\
    \  , 215.84656  ],\n          [289.25125  , 215.84656  ],\n          [289.25125\
    \  , 215.84656  ]]],\n\n\n        [[[ 21.463701 ,  20.093737 ],\n          [ 53.495163\
    \ ,  18.151373 ],\n          [ 90.28387  ,  19.31472  ],\n          ...,\n   \
    \       [296.7474   , 212.16527  ],\n          [296.7474   , 212.16527  ],\n \
    \         [296.7474   , 212.16527  ]],\n\n         [[ 23.726748 ,  20.457853 ],\n\
    \          [ 55.9512   ,  18.359625 ],\n          [ 93.59017  ,  19.048363 ],\n\
    \          ...,\n          [299.61877  , 212.90288  ],\n          [299.61877 \
    \ , 212.90288  ],\n          [299.61877  , 212.90288  ]]]],\n\n\n\n       [[[[\
    \ 12.834421 ,  17.110876 ],\n          [ 48.11179  ,  12.378236 ],\n         \
    \ [ 15.372802 ,  48.307243 ],\n          ...,\n          [310.36115  , 218.85483\
    \  ],\n          [310.36115  , 218.85483  ],\n          [310.36115  , 218.85483\
    \  ]],\n\n         [[ 16.102102 ,  17.28534  ],\n          [ 51.434856 ,  12.241024\
    \ ],\n          [ 19.000374 ,  48.912315 ],\n          ...,\n          [315.83875\
    \  , 219.06664  ],\n          [315.83875  , 219.06664  ],\n          [315.83875\
    \  , 219.06664  ]]],\n\n\n        [[[110.18371  ,  10.850076 ],\n          [141.35196\
    \  ,  11.895993 ],\n          [176.34192  ,  12.915066 ],\n          ...,\n  \
    \        [292.71948  , 238.82951  ],\n          [292.71948  , 238.82951  ],\n\
    \          [292.71948  , 238.82951  ]],\n\n         [[113.75649  ,  10.338397\
    \ ],\n          [144.52837  ,  11.795157 ],\n          [179.2433   ,  13.201189\
    \ ],\n          ...,\n          [296.04565  , 239.96617  ],\n          [296.04565\
    \  , 239.96617  ],\n          [296.04565  , 239.96617  ]]]],\n\n\n\n       ...,\n\
    \n\n\n       [[[[ 29.264444 ,  27.594193 ],\n          [ 59.37066  ,  22.607704\
    \ ],\n          [ 92.61934  ,  20.123547 ],\n          ...,\n          [302.73752\
    \  , 219.94563  ],\n          [302.73752  , 219.94563  ],\n          [302.73752\
    \  , 219.94563  ]],\n\n         [[ 31.198486 ,  26.900785 ],\n          [ 61.469906\
    \ ,  22.865114 ],\n          [ 95.30444  ,  18.703093 ],\n          ...,\n   \
    \       [303.93527  , 219.37537  ],\n          [303.93527  , 219.37537  ],\n \
    \         [303.93527  , 219.37537  ]]],\n\n\n        [[[ 13.995715 ,  30.940674\
    \ ],\n          [ 49.50938  ,  29.792355 ],\n          [ 80.533966 ,  27.898819\
    \ ],\n          ...,\n          [287.0645   , 211.03662  ],\n          [287.0645\
    \   , 211.03662  ],\n          [287.0645   , 211.03662  ]],\n\n         [[ 16.650457\
    \ ,  31.252083 ],\n          [ 50.943314 ,  30.614689 ],\n          [ 81.5372\
    \   ,  27.397314 ],\n          ...,\n          [290.72592  , 211.43758  ],\n \
    \         [290.72592  , 211.43758  ],\n          [290.72592  , 211.43758  ]]]],\n\
    \n\n\n       [[[[ 14.385406 ,  10.196509 ],\n          [ 46.726044 ,   9.964459\
    \ ],\n          [ 78.67092  ,  11.717115 ],\n          ...,\n          [301.77692\
    \  , 236.2078   ],\n          [301.77692  , 236.2078   ],\n          [301.77692\
    \  , 236.2078   ]],\n\n         [[ 17.763153 ,  10.344946 ],\n          [ 51.03203\
    \  ,   9.3839   ],\n          [ 82.088066 ,  10.593551 ],\n          ...,\n  \
    \        [305.81635  , 236.41139  ],\n          [305.81635  , 236.41139  ],\n\
    \          [305.81635  , 236.41139  ]]],\n\n\n        [[[ 30.039707 ,  11.374136\
    \ ],\n          [ 66.340096 ,  10.802025 ],\n          [ 30.837173 ,  44.513794\
    \ ],\n          ...,\n          [293.98846  , 226.89108  ],\n          [293.98846\
    \  , 226.89108  ],\n          [293.98846  , 226.89108  ]],\n\n         [[ 32.86302\
    \  ,  13.149588 ],\n          [ 69.5295   ,  10.044109 ],\n          [ 33.781303\
    \ ,  44.75508  ],\n          ...,\n          [297.00058  , 226.20291  ],\n   \
    \       [297.00058  , 226.20291  ],\n          [297.00058  , 226.20291  ]]]],\n\
    \n\n\n       [[[[280.4922   ,  10.610494 ],\n          [314.41882  ,  12.649813\
    \ ],\n          [ 36.320324 ,  35.210136 ],\n          ...,\n          [233.9313\
    \   , 239.9802   ],\n          [233.9313   , 239.9802   ],\n          [233.9313\
    \   , 239.9802   ]],\n\n         [[283.2211   ,  11.142171 ],\n          [318.47006\
    \  ,  13.071643 ],\n          [ 37.741108 ,  33.852016 ],\n          ...,\n  \
    \        [237.42488  , 240.01611  ],\n          [237.42488  , 240.01611  ],\n\
    \          [237.42488  , 240.01611  ]]],\n\n\n        [[[  7.02307  ,  32.780872\
    \ ],\n          [ 41.997185 ,  28.719297 ],\n          [ 75.99742  ,  26.995586\
    \ ],\n          ...,\n          [292.5279   , 238.76224  ],\n          [292.5279\
    \   , 238.76224  ],\n          [292.5279   , 238.76224  ]],\n\n         [[ 10.774257\
    \ ,  32.79069  ],\n          [ 45.20355  ,  29.783785 ],\n          [ 78.753456\
    \ ,  27.710579 ],\n          ...,\n          [296.80423  , 238.13068  ],\n   \
    \       [296.80423  , 238.13068  ],\n          [296.80423  , 238.13068  ]]]]],\
    \ dtype=float32))])"
_last_episode_starts:
  desc: null
  value: '[ True  True  True  True  True  True  True  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: 'Dict(''gt_offset'': Box(-3.4028235e+38, 3.4028235e+38, (3,), float32), ''marker_flow'':
    Box(-3.4028235e+38, 3.4028235e+38, (2, 2, 128, 2), float32))'
action_space:
  desc: null
  value: Box(-1.0, 1.0, (3,), float32)
n_envs:
  desc: null
  value: 10
buffer_size:
  desc: null
  value: 200000
batch_size:
  desc: null
  value: 256
learning_starts:
  desc: null
  value: 2000
tau:
  desc: null
  value: 0.005
gamma:
  desc: null
  value: 0.99
gradient_steps:
  desc: null
  value: -1
optimize_memory_usage:
  desc: null
  value: 'False'
replay_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.DictReplayBuffer object at 0x7f7c84e9bf70>
replay_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.DictReplayBuffer'>
replay_buffer_kwargs:
  desc: null
  value: '{}'
_episode_storage:
  desc: null
  value: None
train_freq:
  desc: null
  value: 'TrainFreq(frequency=2, unit=<TrainFrequencyUnit.STEP: ''step''>)'
use_sde_at_warmup:
  desc: null
  value: 'False'
target_entropy:
  desc: null
  value: -3.0
log_ent_coef:
  desc: null
  value: tensor([0.], device='cuda:0', requires_grad=True)
ent_coef:
  desc: null
  value: auto
target_update_interval:
  desc: null
  value: 1
ent_coef_optimizer:
  desc: null
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay:\
    \ 0\n)"
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x7f7c84ea9bd0>
actor:
  desc: null
  value: "Actor(\n  (features_extractor): FeatureExtractorWithPointNetEncoder(\n \
    \   (feature_extractor_net): PointNetFeatureExtractor(\n      (pointnet_local_fea):\
    \ Sequential(\n        (0): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n   \
    \     (1): Identity()\n        (2): ReLU()\n        (3): Conv1d(64, 64, kernel_size=(1,),\
    \ stride=(1,))\n        (4): Identity()\n        (5): ReLU()\n      )\n      (pointnet_global_fea):\
    \ PointNetFeaNew(\n        (conv0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n\
    \        (bn0): Identity()\n        (conv1): Conv1d(64, 128, kernel_size=(1,),\
    \ stride=(1,))\n        (bn1): Identity()\n        (conv2): Conv1d(128, 512, kernel_size=(1,),\
    \ stride=(1,))\n        (bn2): Identity()\n      )\n      (mlp_output): Sequential(\n\
    \        (0): Linear(in_features=512, out_features=256, bias=True)\n        (1):\
    \ ReLU()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \        (3): ReLU()\n        (4): Linear(in_features=256, out_features=32, bias=True)\n\
    \      )\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=64,\
    \ out_features=256, bias=True)\n    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n\
    \    (2): ReLU()\n    (3): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (5): ReLU()\n\
    \    (6): Linear(in_features=256, out_features=256, bias=True)\n    (7): Tanh()\n\
    \  )\n  (mu): Linear(in_features=256, out_features=3, bias=True)\n  (log_std):\
    \ Linear(in_features=256, out_features=3, bias=True)\n)"
critic:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
critic_target:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
batch_norm_stats:
  desc: null
  value: '[]'
batch_norm_stats_target:
  desc: null
  value: '[]'
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7f7c81200c70>
