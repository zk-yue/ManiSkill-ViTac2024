wandb_version: 1

env:
  desc: null
  value:
    step_penalty: 1
    final_reward: 10
    max_action:
    - 2.0
    - 2.0
    - 4.0
    max_steps: 8
    z_step_size: 0.125
    peg_hole_path_file: configs/peg_insertion/3shape_2.0mm.txt
    peg_x_max_offset: 5.0
    peg_y_max_offset: 5.0
    peg_theta_max_offset: 10.0
    marker_interval_range:
    - 1.95
    - 2.15
    marker_rotation_range: 0.1
    marker_translation_range:
    - 1
    - 1
    marker_pos_shift_range:
    - 0.1
    - 0.1
    marker_random_noise: 0.5
    marker_lose_tracking_probability: 0.01
    normalize: false
policy:
  desc: null
  value:
    buffer_size: 200000
    train_freq: 2
    gradient_steps: -1
    learning_starts: 2000
    action_noise: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5
      0.5])), n_envs=12)
    batch_size: 512
    learning_rate: 0.0001
    optimize_memory_usage: false
    ent_coef: auto
    target_update_interval: 1
    target_entropy: auto
    use_sde: false
    sde_sample_freq: -1
    use_sde_at_warmup: false
    policy_kwargs:
      pointnet_in_dim: 4
      pointnet_out_dim: 32
      pointnet_batchnorm: false
      pointnet_layernorm: true
      zero_init_output: true
      use_sde: false
    device: cuda:0
    seed: 0
    tensorboard_log: /media/lab/data/yzk/ManiSkill-ViTac2024/scripts/../training_log/3shape_2.0mm_2024-03-17_21-49-25.885
train:
  desc: null
  value:
    total_timesteps: 500000
    log_interval: 10
    checkpoint_every: 2000
    eval_freq: 2000
    n_eval: 50
    parallel: 12
    seed: 0
    device: cuda:0
    gpu: 0
    name: 3shape_2.0mm
    wandb_name: ManiSkill_ViTac
    emp: {}
cfg:
  desc: null
  value: configs/parameters/peg_insertion_sac.yaml
no_render:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    code_path: code/scripts/train_sac.py
    python_version: 3.10.0
    cli_version: 0.16.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1710683372.426232
    t:
      1:
      - 1
      - 5
      - 53
      - 55
      2:
      - 1
      - 5
      - 53
      - 55
      3:
      - 13
      - 16
      - 22
      - 23
      - 35
      4: 3.10.0
      5: 0.16.0
      8:
      - 5
      13: linux-x86_64
algo:
  desc: null
  value: SAC
policy_class:
  desc: null
  value: <class 'solutions.policies_sac.SACPolicyForPointFlowEnv'>
device:
  desc: null
  value: cuda:0
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{''pointnet_in_dim'': 4, ''pointnet_out_dim'': 32, ''pointnet_batchnorm'':
    False, ''pointnet_layernorm'': True, ''zero_init_output'': True, ''use_sde'':
    False}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 500000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: 0
action_noise:
  desc: null
  value: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5 0.5])), n_envs=12)
start_time:
  desc: null
  value: 1710683377139390845
learning_rate:
  desc: null
  value: 0.0001
tensorboard_log:
  desc: null
  value: /media/lab/data/yzk/ManiSkill-ViTac2024/scripts/../training_log/3shape_2.0mm_2024-03-17_21-49-25.885
_last_obs:
  desc: null
  value: "OrderedDict([('gt_offset', array([[-3.1487968 ,  1.5482761 ,  6.0068126\
    \ ],\n       [ 0.93601006,  3.6674595 , -7.1389513 ],\n       [ 3.173014  , -0.6716256\
    \ ,  3.676935  ],\n       [-3.3719926 ,  2.4098825 ,  2.1999123 ],\n       [ 1.2634326\
    \ , -0.5410738 ,  3.496989  ],\n       [-1.6554956 , -2.9915373 , -7.7654576 ],\n\
    \       [ 3.9156    ,  0.5691094 , -2.5115135 ],\n       [ 3.3624942 , -0.97113806,\
    \ -8.529218  ],\n       [-0.795557  , -2.3646386 , -4.485393  ],\n       [-0.10903402,\
    \  2.2377715 , -2.594263  ],\n       [-2.8694549 , -2.4829504 ,  5.2776704 ],\n\
    \       [ 1.3828931 ,  0.94206935,  3.1704328 ]], dtype=float32)), ('marker_flow',\
    \ array([[[[[244.0834   ,  10.479672 ],\n          [311.62234  ,  14.740108 ],\n\
    \          [ 37.14107  ,  40.843163 ],\n          ...,\n          [138.21259 \
    \ , 239.09271  ],\n          [138.21259  , 239.09271  ],\n          [138.21259\
    \  , 239.09271  ]],\n\n         [[248.82686  ,   9.804139 ],\n          [313.8399\
    \   ,  15.092239 ],\n          [ 41.49962  ,  40.1935   ],\n          ...,\n \
    \         [142.66745  , 239.17397  ],\n          [142.66745  , 239.17397  ],\n\
    \          [142.66745  , 239.17397  ]]],\n\n\n        [[[ 85.725464 ,  10.585327\
    \ ],\n          [119.287155 ,  13.626207 ],\n          [149.08434  ,  15.197167\
    \ ],\n          ...,\n          [195.03018  , 237.0759   ],\n          [195.03018\
    \  , 237.0759   ],\n          [195.03018  , 237.0759   ]],\n\n         [[ 89.541565\
    \ ,   9.819723 ],\n          [122.08232  ,  14.428548 ],\n          [153.10913\
    \  ,  15.226886 ],\n          ...,\n          [199.17607  , 237.38766  ],\n  \
    \        [199.17607  , 237.38766  ],\n          [199.17607  , 237.38766  ]]]],\n\
    \n\n\n       [[[[ 25.302683 ,  27.988276 ],\n          [ 59.67552  ,  29.336126\
    \ ],\n          [ 94.08705  ,  27.59701  ],\n          ...,\n          [297.04855\
    \  , 212.99483  ],\n          [297.04855  , 212.99483  ],\n          [297.04855\
    \  , 212.99483  ]],\n\n         [[ 27.61082  ,  27.99714  ],\n          [ 62.424656\
    \ ,  29.171686 ],\n          [ 96.356766 ,  27.122576 ],\n          ...,\n   \
    \       [299.09753  , 213.60547  ],\n          [299.09753  , 213.60547  ],\n \
    \         [299.09753  , 213.60547  ]]],\n\n\n        [[[ 18.18833  ,  18.995907\
    \ ],\n          [ 49.2127   ,  17.948399 ],\n          [ 83.5434   ,  17.576231\
    \ ],\n          ...,\n          [308.74573  , 208.02573  ],\n          [308.74573\
    \  , 208.02573  ],\n          [308.74573  , 208.02573  ]],\n\n         [[ 19.848387\
    \ ,  18.99959  ],\n          [ 53.01591  ,  18.370157 ],\n          [ 86.93317\
    \  ,  16.531626 ],\n          ...,\n          [311.46445  , 208.24977  ],\n  \
    \        [311.46445  , 208.24977  ],\n          [311.46445  , 208.24977  ]]]],\n\
    \n\n\n       [[[[ 13.978126 ,  15.689855 ],\n          [ 45.46257  ,  15.062095\
    \ ],\n          [ 81.08051  ,  14.810581 ],\n          ...,\n          [289.69757\
    \  , 226.02626  ],\n          [289.69757  , 226.02626  ],\n          [289.69757\
    \  , 226.02626  ]],\n\n         [[ 15.4615135,  16.072845 ],\n          [ 48.420662\
    \ ,  14.927135 ],\n          [ 83.42921  ,  16.39809  ],\n          ...,\n   \
    \       [291.6748   , 225.7748   ],\n          [291.6748   , 225.7748   ],\n \
    \         [291.6748   , 225.7748   ]]],\n\n\n        [[[ 95.68207  ,  14.489391\
    \ ],\n          [128.24367  ,  17.07908  ],\n          [163.19891  ,  20.547565\
    \ ],\n          ...,\n          [282.02747  , 231.42848  ],\n          [282.02747\
    \  , 231.42848  ],\n          [282.02747  , 231.42848  ]],\n\n         [[ 98.305115\
    \ ,  14.50863  ],\n          [132.20712  ,  17.548754 ],\n          [166.20674\
    \  ,  19.987032 ],\n          ...,\n          [284.09824  , 230.92015  ],\n  \
    \        [284.09824  , 230.92015  ],\n          [284.09824  , 230.92015  ]]]],\n\
    \n\n\n       ...,\n\n\n\n       [[[[105.77406  ,  10.097548 ],\n          [138.50076\
    \  ,  14.173194 ],\n          [172.38867  ,  14.084797 ],\n          ...,\n  \
    \        [152.59608  , 239.44423  ],\n          [152.59608  , 239.44423  ],\n\
    \          [152.59608  , 239.44423  ]],\n\n         [[108.586235 ,  10.357623\
    \ ],\n          [141.72897  ,  13.570353 ],\n          [175.51814  ,  14.987734\
    \ ],\n          ...,\n          [156.29442  , 239.40636  ],\n          [156.29442\
    \  , 239.40636  ],\n          [156.29442  , 239.40636  ]]],\n\n\n        [[[ 32.995388\
    \ ,  30.958904 ],\n          [ 63.47151  ,  30.324057 ],\n          [ 97.79733\
    \  ,  30.041807 ],\n          ...,\n          [284.43408  , 221.83841  ],\n  \
    \        [284.43408  , 221.83841  ],\n          [284.43408  , 221.83841  ]],\n\
    \n         [[ 35.021404 ,  31.900309 ],\n          [ 67.72674  ,  29.204266 ],\n\
    \          [100.92984  ,  31.357445 ],\n          ...,\n          [288.14517 \
    \ , 221.24603  ],\n          [288.14517  , 221.24603  ],\n          [288.14517\
    \  , 221.24603  ]]]],\n\n\n\n       [[[[ 20.354038 ,  29.88823  ],\n         \
    \ [ 56.403484 ,  28.034735 ],\n          [ 88.19532  ,  28.796589 ],\n       \
    \   ...,\n          [278.56384  , 211.12263  ],\n          [278.56384  , 211.12263\
    \  ],\n          [278.56384  , 211.12263  ]],\n\n         [[ 23.845026 ,  29.147709\
    \ ],\n          [ 58.170876 ,  29.181744 ],\n          [ 90.791794 ,  28.782448\
    \ ],\n          ...,\n          [282.5652   , 212.02043  ],\n          [282.5652\
    \   , 212.02043  ],\n          [282.5652   , 212.02043  ]]],\n\n\n        [[[\
    \ 23.156914 ,  12.688691 ],\n          [ 23.954762 ,  45.118687 ],\n         \
    \ [ 56.00656  ,  45.23007  ],\n          ...,\n          [299.67252  , 221.28397\
    \  ],\n          [299.67252  , 221.28397  ],\n          [299.67252  , 221.28397\
    \  ]],\n\n         [[ 24.558886 ,  12.625305 ],\n          [ 27.442652 ,  45.500965\
    \ ],\n          [ 59.05364  ,  44.067383 ],\n          ...,\n          [303.25162\
    \  , 221.93388  ],\n          [303.25162  , 221.93388  ],\n          [303.25162\
    \  , 221.93388  ]]]],\n\n\n\n       [[[[ 25.285938 ,  15.406125 ],\n         \
    \ [ 57.463947 ,  13.779692 ],\n          [ 89.987465 ,  13.696293 ],\n       \
    \   ...,\n          [290.47864  , 220.19524  ],\n          [290.47864  , 220.19524\
    \  ],\n          [290.47864  , 220.19524  ]],\n\n         [[ 28.054226 ,  15.734499\
    \ ],\n          [ 60.65449  ,  14.496304 ],\n          [ 92.63482  ,  13.731257\
    \ ],\n          ...,\n          [292.88464  , 220.76971  ],\n          [292.88464\
    \  , 220.76971  ],\n          [292.88464  , 220.76971  ]]],\n\n\n        [[[ 17.530468\
    \ ,  14.294939 ],\n          [ 50.97197  ,  15.163665 ],\n          [ 82.87465\
    \  ,  18.458986 ],\n          ...,\n          [ 67.567604 , 237.67789  ],\n  \
    \        [ 67.567604 , 237.67789  ],\n          [ 67.567604 , 237.67789  ]],\n\
    \n         [[ 19.758759 ,  13.506176 ],\n          [ 52.553253 ,  15.237295 ],\n\
    \          [ 85.10506  ,  17.719334 ],\n          ...,\n          [ 69.7531  \
    \ , 237.01743  ],\n          [ 69.7531   , 237.01743  ],\n          [ 69.7531\
    \   , 237.01743  ]]]]], dtype=float32))])"
_last_episode_starts:
  desc: null
  value: '[ True  True  True  True  True  True  True  True  True  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: 'Dict(''gt_offset'': Box(-3.4028235e+38, 3.4028235e+38, (3,), float32), ''marker_flow'':
    Box(-3.4028235e+38, 3.4028235e+38, (2, 2, 128, 2), float32))'
action_space:
  desc: null
  value: Box(-1.0, 1.0, (3,), float32)
n_envs:
  desc: null
  value: 12
buffer_size:
  desc: null
  value: 200000
batch_size:
  desc: null
  value: 512
learning_starts:
  desc: null
  value: 2000
tau:
  desc: null
  value: 0.005
gamma:
  desc: null
  value: 0.99
gradient_steps:
  desc: null
  value: -1
optimize_memory_usage:
  desc: null
  value: 'False'
replay_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.DictReplayBuffer object at 0x7ff7192cd720>
replay_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.DictReplayBuffer'>
replay_buffer_kwargs:
  desc: null
  value: '{}'
_episode_storage:
  desc: null
  value: None
train_freq:
  desc: null
  value: 'TrainFreq(frequency=2, unit=<TrainFrequencyUnit.STEP: ''step''>)'
use_sde_at_warmup:
  desc: null
  value: 'False'
target_entropy:
  desc: null
  value: -3.0
log_ent_coef:
  desc: null
  value: tensor([0.], device='cuda:0', requires_grad=True)
ent_coef:
  desc: null
  value: auto
target_update_interval:
  desc: null
  value: 1
ent_coef_optimizer:
  desc: null
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay:\
    \ 0\n)"
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x7ff7192e1cf0>
actor:
  desc: null
  value: "Actor(\n  (features_extractor): FeatureExtractorWithPointNetEncoder(\n \
    \   (feature_extractor_net): PointNetFeatureExtractor(\n      (pointnet_local_fea):\
    \ Sequential(\n        (0): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n   \
    \     (1): Identity()\n        (2): ReLU()\n        (3): Conv1d(64, 64, kernel_size=(1,),\
    \ stride=(1,))\n        (4): Identity()\n        (5): ReLU()\n      )\n      (pointnet_global_fea):\
    \ PointNetFeaNew(\n        (conv0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n\
    \        (bn0): Identity()\n        (conv1): Conv1d(64, 128, kernel_size=(1,),\
    \ stride=(1,))\n        (bn1): Identity()\n        (conv2): Conv1d(128, 512, kernel_size=(1,),\
    \ stride=(1,))\n        (bn2): Identity()\n      )\n      (mlp_output): Sequential(\n\
    \        (0): Linear(in_features=512, out_features=256, bias=True)\n        (1):\
    \ ReLU()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \        (3): ReLU()\n        (4): Linear(in_features=256, out_features=32, bias=True)\n\
    \      )\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=64,\
    \ out_features=256, bias=True)\n    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n\
    \    (2): ReLU()\n    (3): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (5): ReLU()\n\
    \    (6): Linear(in_features=256, out_features=256, bias=True)\n    (7): Tanh()\n\
    \  )\n  (mu): Linear(in_features=256, out_features=3, bias=True)\n  (log_std):\
    \ Linear(in_features=256, out_features=3, bias=True)\n)"
critic:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
critic_target:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
batch_norm_stats:
  desc: null
  value: '[]'
batch_norm_stats_target:
  desc: null
  value: '[]'
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7ff70889d030>
