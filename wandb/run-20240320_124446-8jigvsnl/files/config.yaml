wandb_version: 1

env:
  desc: null
  value:
    step_penalty: 1
    final_reward: 10
    max_action:
    - 2.0
    - 2.0
    - 4.0
    max_steps: 8
    z_step_size: 0.125
    peg_hole_path_file: configs/peg_insertion/3shape_1.5mm.txt
    peg_x_max_offset: 5.0
    peg_y_max_offset: 5.0
    peg_theta_max_offset: 10.0
    marker_interval_range:
    - 1.95
    - 2.15
    marker_rotation_range: 0.1
    marker_translation_range:
    - 1
    - 1
    marker_pos_shift_range:
    - 0.1
    - 0.1
    marker_random_noise: 0.5
    marker_lose_tracking_probability: 0.01
    normalize: false
policy:
  desc: null
  value:
    buffer_size: 200000
    train_freq: 2
    gradient_steps: -1
    learning_starts: 2000
    action_noise: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5
      0.5])), n_envs=12)
    batch_size: 512
    learning_rate: 0.0001
    optimize_memory_usage: false
    ent_coef: auto
    target_update_interval: 1
    target_entropy: auto
    use_sde: false
    sde_sample_freq: -1
    use_sde_at_warmup: false
    policy_kwargs:
      pointnet_in_dim: 4
      pointnet_out_dim: 32
      pointnet_batchnorm: false
      pointnet_layernorm: true
      zero_init_output: true
      use_sde: false
    device: cuda:0
    seed: 0
    tensorboard_log: /home/lab404/YZK/ManiSkill_Vitac/ManiSkill-ViTac2024/scripts/../training_log/3shape_1.5mm_batch_size_512_lr_0.0001_2024-03-20_12-44-36.297
train:
  desc: null
  value:
    total_timesteps: 500000
    log_interval: 6
    checkpoint_every: 2000
    eval_freq: 2000
    n_eval: 50
    parallel: 12
    seed: 0
    device: cuda:0
    gpu: 0
    name: 3shape_1.5mm_batch_size_512_lr_0.0001
    wandb_name: ManiSkill_ViTac
    emp: {}
cfg:
  desc: null
  value: configs/parameters/peg_insertion_sac.yaml
no_render:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    code_path: code/scripts/train_sac.py
    python_version: 3.10.0
    cli_version: 0.16.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1710909886.934277
    t:
      1:
      - 1
      - 5
      - 53
      - 55
      2:
      - 1
      - 5
      - 53
      - 55
      3:
      - 13
      - 16
      - 22
      - 23
      - 35
      4: 3.10.0
      5: 0.16.0
      8:
      - 5
      13: linux-x86_64
algo:
  desc: null
  value: SAC
policy_class:
  desc: null
  value: <class 'solutions.policies_sac.SACPolicyForPointFlowEnv'>
device:
  desc: null
  value: cuda:0
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{''pointnet_in_dim'': 4, ''pointnet_out_dim'': 32, ''pointnet_batchnorm'':
    False, ''pointnet_layernorm'': True, ''zero_init_output'': True, ''use_sde'':
    False}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 500000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: 0
action_noise:
  desc: null
  value: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5 0.5])), n_envs=12)
start_time:
  desc: null
  value: 1710909917629985215
learning_rate:
  desc: null
  value: 0.0001
tensorboard_log:
  desc: null
  value: /home/lab404/YZK/ManiSkill_Vitac/ManiSkill-ViTac2024/scripts/../training_log/3shape_1.5mm_batch_size_512_lr_0.0001_2024-03-20_12-44-36.297
_last_obs:
  desc: null
  value: "OrderedDict([('gt_offset', array([[ 3.8180099 ,  2.8121295 ,  2.2851663\
    \ ],\n       [ 3.497618  ,  3.9420774 , -5.167306  ],\n       [ 4.051801  ,  0.6847738\
    \ , -9.463903  ],\n       [ 1.6425505 , -3.5945287 , -7.2116914 ],\n       [-0.7577233\
    \ , -3.551335  , -7.5535693 ],\n       [ 0.83961225, -1.7585664 , -4.669847  ],\n\
    \       [ 3.4655643 ,  2.7408319 , -0.6293454 ],\n       [-1.3080802 , -1.7271392\
    \ ,  9.983162  ],\n       [ 1.3429996 ,  4.790683  ,  1.1958959 ],\n       [ 1.7243054\
    \ , -0.1721895 ,  8.07354   ],\n       [-3.383763  , -1.8306903 , -5.915664  ],\n\
    \       [-3.6465929 , -3.0503974 ,  9.1659155 ]], dtype=float32)), ('marker_flow',\
    \ array([[[[[ 28.121181 ,  11.218736 ],\n          [ 63.641834 ,   9.949702 ],\n\
    \          [ 34.10178  ,  41.397358 ],\n          ...,\n          [304.757   \
    \ , 211.94838  ],\n          [304.757    , 211.94838  ],\n          [304.757 \
    \   , 211.94838  ]],\n\n         [[ 31.240229 ,  11.88022  ],\n          [ 66.62184\
    \  ,   9.458734 ],\n          [ 36.513626 ,  42.37766  ],\n          ...,\n  \
    \        [307.9269   , 212.45879  ],\n          [307.9269   , 212.45879  ],\n\
    \          [307.9269   , 212.45879  ]]],\n\n\n        [[[ 32.726437 ,  27.587809\
    \ ],\n          [ 62.6636   ,  26.796782 ],\n          [ 96.23518  ,  24.42391\
    \  ],\n          ...,\n          [299.89084  , 227.85094  ],\n          [299.89084\
    \  , 227.85094  ],\n          [299.89084  , 227.85094  ]],\n\n         [[ 35.50354\
    \  ,  29.157713 ],\n          [ 66.08937  ,  26.975552 ],\n          [ 99.38163\
    \  ,  25.518717 ],\n          ...,\n          [304.0861   , 227.44302  ],\n  \
    \        [304.0861   , 227.44302  ],\n          [304.0861   , 227.44302  ]]]],\n\
    \n\n\n       [[[[212.15858  ,  11.686552 ],\n          [245.00334  ,  14.059756\
    \ ],\n          [276.39178  ,  17.105032 ],\n          ...,\n          [290.2343\
    \   , 233.12703  ],\n          [290.2343   , 233.12703  ],\n          [290.2343\
    \   , 233.12703  ]],\n\n         [[216.22673  ,  11.139824 ],\n          [248.54306\
    \  ,  12.938786 ],\n          [280.9278   ,  17.089348 ],\n          ...,\n  \
    \        [292.93982  , 232.85007  ],\n          [292.93982  , 232.85007  ],\n\
    \          [292.93982  , 232.85007  ]]],\n\n\n        [[[161.39166  ,  15.31868\
    \  ],\n          [193.5009   ,  18.992622 ],\n          [227.35408  ,  22.053507\
    \ ],\n          ...,\n          [137.24516  , 239.17332  ],\n          [137.24516\
    \  , 239.17332  ],\n          [137.24516  , 239.17332  ]],\n\n         [[164.14949\
    \  ,  14.960391 ],\n          [196.9292   ,  17.10108  ],\n          [231.22505\
    \  ,  22.022335 ],\n          ...,\n          [139.99512  , 238.5777   ],\n  \
    \        [139.99512  , 238.5777   ],\n          [139.99512  , 238.5777   ]]]],\n\
    \n\n\n       [[[[ 29.626225 ,  29.545784 ],\n          [ 62.87408  ,  26.478567\
    \ ],\n          [ 96.06909  ,  26.191725 ],\n          ...,\n          [280.8095\
    \   , 231.286    ],\n          [280.8095   , 231.286    ],\n          [280.8095\
    \   , 231.286    ]],\n\n         [[ 32.91413  ,  28.691986 ],\n          [ 66.57326\
    \  ,  26.473288 ],\n          [ 98.5152   ,  25.393496 ],\n          ...,\n  \
    \        [284.0883   , 230.57545  ],\n          [284.0883   , 230.57545  ],\n\
    \          [284.0883   , 230.57545  ]]],\n\n\n        [[[ 37.68424  ,  30.252766\
    \ ],\n          [ 72.72097  ,  29.69107  ],\n          [106.78202  ,  25.300377\
    \ ],\n          ...,\n          [283.61615  , 209.71579  ],\n          [283.61615\
    \  , 209.71579  ],\n          [283.61615  , 209.71579  ]],\n\n         [[ 41.140156\
    \ ,  30.835798 ],\n          [ 76.48872  ,  29.52538  ],\n          [109.69585\
    \  ,  25.750635 ],\n          ...,\n          [286.3646   , 211.74303  ],\n  \
    \        [286.3646   , 211.74303  ],\n          [286.3646   , 211.74303  ]]]],\n\
    \n\n\n       ...,\n\n\n\n       [[[[ 25.663107 ,  33.79228  ],\n          [ 57.18061\
    \  ,  34.931274 ],\n          [ 92.22283  ,  33.72141  ],\n          ...,\n  \
    \        [291.2245   , 226.59409  ],\n          [291.2245   , 226.59409  ],\n\
    \          [291.2245   , 226.59409  ]],\n\n         [[ 28.257473 ,  33.960846\
    \ ],\n          [ 59.77837  ,  34.83548  ],\n          [ 95.79601  ,  34.14309\
    \  ],\n          ...,\n          [292.93677  , 226.36401  ],\n          [292.93677\
    \  , 226.36401  ],\n          [292.93677  , 226.36401  ]]],\n\n\n        [[[ 37.88895\
    \  ,  43.406193 ],\n          [ 71.34246  ,  41.77274  ],\n          [106.097176\
    \ ,  38.939224 ],\n          ...,\n          [292.28357  , 224.58307  ],\n   \
    \       [292.28357  , 224.58307  ],\n          [292.28357  , 224.58307  ]],\n\n\
    \         [[ 42.156757 ,  42.914494 ],\n          [ 74.18738  ,  42.654118 ],\n\
    \          [110.51932  ,  39.27086  ],\n          ...,\n          [295.746   \
    \ , 225.51271  ],\n          [295.746    , 225.51271  ],\n          [295.746 \
    \   , 225.51271  ]]]],\n\n\n\n       [[[[ 36.101044 ,  38.154713 ],\n        \
    \  [ 67.224464 ,  37.25922  ],\n          [ 99.45793  ,  37.035954 ],\n      \
    \    ...,\n          [261.81357  , 216.13625  ],\n          [261.81357  , 216.13625\
    \  ],\n          [261.81357  , 216.13625  ]],\n\n         [[ 38.464386 ,  37.41487\
    \  ],\n          [ 71.0149   ,  36.33652  ],\n          [102.77227  ,  36.288525\
    \ ],\n          ...,\n          [264.84265  , 216.55978  ],\n          [264.84265\
    \  , 216.55978  ],\n          [264.84265  , 216.55978  ]]],\n\n\n        [[[249.45415\
    \  ,  14.452253 ],\n          [282.22186  ,  14.792088 ],\n          [ 12.306772\
    \ ,  27.355816 ],\n          ...,\n          [196.42493  , 235.17834  ],\n   \
    \       [196.42493  , 235.17834  ],\n          [196.42493  , 235.17834  ]],\n\n\
    \         [[253.45691  ,  15.49555  ],\n          [285.94116  ,  15.413946 ],\n\
    \          [ 15.819826 ,  26.860899 ],\n          ...,\n          [199.39368 \
    \ , 233.99562  ],\n          [199.39368  , 233.99562  ],\n          [199.39368\
    \  , 233.99562  ]]]],\n\n\n\n       [[[[  4.9260235,  19.91142  ],\n         \
    \ [ 36.93697  ,  15.418812 ],\n          [ 69.13522  ,  14.379025 ],\n       \
    \   ...,\n          [309.19037  , 206.24142  ],\n          [309.19037  , 206.24142\
    \  ],\n          [309.19037  , 206.24142  ]],\n\n         [[  9.525482 ,  19.649601\
    \ ],\n          [ 40.41695  ,  15.771563 ],\n          [ 74.108345 ,  13.1635475],\n\
    \          ...,\n          [311.845    , 206.46106  ],\n          [311.845   \
    \ , 206.46106  ],\n          [311.845    , 206.46106  ]]],\n\n\n        [[[ 14.274636\
    \ ,  21.146687 ],\n          [ 49.316875 ,  21.819405 ],\n          [ 80.47793\
    \  ,  25.045818 ],\n          ...,\n          [299.2413   , 227.09271  ],\n  \
    \        [299.2413   , 227.09271  ],\n          [299.2413   , 227.09271  ]],\n\
    \n         [[ 18.036709 ,  22.250563 ],\n          [ 52.723167 ,  22.659376 ],\n\
    \          [ 86.05593  ,  24.12023  ],\n          ...,\n          [299.82654 \
    \ , 226.64961  ],\n          [299.82654  , 226.64961  ],\n          [299.82654\
    \  , 226.64961  ]]]]], dtype=float32))])"
_last_episode_starts:
  desc: null
  value: '[ True  True  True  True  True  True  True  True  True  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: 'Dict(''gt_offset'': Box(-3.4028235e+38, 3.4028235e+38, (3,), float32), ''marker_flow'':
    Box(-3.4028235e+38, 3.4028235e+38, (2, 2, 128, 2), float32))'
action_space:
  desc: null
  value: Box(-1.0, 1.0, (3,), float32)
n_envs:
  desc: null
  value: 12
buffer_size:
  desc: null
  value: 200000
batch_size:
  desc: null
  value: 512
learning_starts:
  desc: null
  value: 2000
tau:
  desc: null
  value: 0.005
gamma:
  desc: null
  value: 0.99
gradient_steps:
  desc: null
  value: -1
optimize_memory_usage:
  desc: null
  value: 'False'
replay_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.DictReplayBuffer object at 0x7f6c19617e50>
replay_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.DictReplayBuffer'>
replay_buffer_kwargs:
  desc: null
  value: '{}'
_episode_storage:
  desc: null
  value: None
train_freq:
  desc: null
  value: 'TrainFreq(frequency=2, unit=<TrainFrequencyUnit.STEP: ''step''>)'
use_sde_at_warmup:
  desc: null
  value: 'False'
target_entropy:
  desc: null
  value: -3.0
log_ent_coef:
  desc: null
  value: tensor([0.], device='cuda:0', requires_grad=True)
ent_coef:
  desc: null
  value: auto
target_update_interval:
  desc: null
  value: 1
ent_coef_optimizer:
  desc: null
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay:\
    \ 0\n)"
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x7f6c1962a3b0>
actor:
  desc: null
  value: "Actor(\n  (features_extractor): FeatureExtractorWithPointNetEncoder(\n \
    \   (feature_extractor_net): PointNetFeatureExtractor(\n      (pointnet_local_fea):\
    \ Sequential(\n        (0): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n   \
    \     (1): Identity()\n        (2): ReLU()\n        (3): Conv1d(64, 64, kernel_size=(1,),\
    \ stride=(1,))\n        (4): Identity()\n        (5): ReLU()\n      )\n      (pointnet_global_fea):\
    \ PointNetFeaNew(\n        (conv0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n\
    \        (bn0): Identity()\n        (conv1): Conv1d(64, 128, kernel_size=(1,),\
    \ stride=(1,))\n        (bn1): Identity()\n        (conv2): Conv1d(128, 512, kernel_size=(1,),\
    \ stride=(1,))\n        (bn2): Identity()\n      )\n      (mlp_output): Sequential(\n\
    \        (0): Linear(in_features=512, out_features=256, bias=True)\n        (1):\
    \ ReLU()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \        (3): ReLU()\n        (4): Linear(in_features=256, out_features=32, bias=True)\n\
    \      )\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=64,\
    \ out_features=256, bias=True)\n    (1): Identity()\n    (2): ReLU()\n    (3):\
    \ Linear(in_features=256, out_features=256, bias=True)\n    (4): Identity()\n\
    \    (5): ReLU()\n    (6): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (7): Tanh()\n  )\n  (mu): Linear(in_features=256, out_features=3, bias=True)\n\
    \  (log_std): Linear(in_features=256, out_features=3, bias=True)\n)"
critic:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
critic_target:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
batch_norm_stats:
  desc: null
  value: '[]'
batch_norm_stats_target:
  desc: null
  value: '[]'
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7f6c25e35f00>
