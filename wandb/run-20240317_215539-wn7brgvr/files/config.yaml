wandb_version: 1

env:
  desc: null
  value:
    step_penalty: 1
    final_reward: 10
    max_action:
    - 2.0
    - 2.0
    - 4.0
    max_steps: 8
    z_step_size: 0.125
    peg_hole_path_file: configs/peg_insertion/3shape_1.5mm.txt
    peg_x_max_offset: 5.0
    peg_y_max_offset: 5.0
    peg_theta_max_offset: 10.0
    marker_interval_range:
    - 1.95
    - 2.15
    marker_rotation_range: 0.1
    marker_translation_range:
    - 1
    - 1
    marker_pos_shift_range:
    - 0.1
    - 0.1
    marker_random_noise: 0.5
    marker_lose_tracking_probability: 0.01
    normalize: false
policy:
  desc: null
  value:
    buffer_size: 200000
    train_freq: 2
    gradient_steps: -1
    learning_starts: 2000
    action_noise: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5
      0.5])), n_envs=12)
    batch_size: 512
    learning_rate: 0.0001
    optimize_memory_usage: false
    ent_coef: auto
    target_update_interval: 1
    target_entropy: auto
    use_sde: false
    sde_sample_freq: -1
    use_sde_at_warmup: false
    policy_kwargs:
      pointnet_in_dim: 4
      pointnet_out_dim: 32
      pointnet_batchnorm: false
      pointnet_layernorm: true
      zero_init_output: true
      use_sde: false
    device: cuda:0
    seed: 0
    tensorboard_log: /media/lab/data/yzk/ManiSkill-ViTac2024/scripts/../training_log/3shape_1.5mm_batch_size_512_lr_0.0001_2024-03-17_21-55-33.140
train:
  desc: null
  value:
    total_timesteps: 500000
    log_interval: 10
    checkpoint_every: 2000
    eval_freq: 2000
    n_eval: 50
    parallel: 12
    seed: 0
    device: cuda:0
    gpu: 0
    name: 3shape_1.5mm_batch_size_512_lr_0.0001
    wandb_name: ManiSkill_ViTac
    emp: {}
cfg:
  desc: null
  value: configs/parameters/peg_insertion_sac.yaml
no_render:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    code_path: code/scripts/train_sac.py
    python_version: 3.10.0
    cli_version: 0.16.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1710683739.463659
    t:
      1:
      - 1
      - 5
      - 53
      - 55
      2:
      - 1
      - 5
      - 53
      - 55
      3:
      - 13
      - 16
      - 22
      - 23
      - 35
      4: 3.10.0
      5: 0.16.0
      8:
      - 5
      13: linux-x86_64
algo:
  desc: null
  value: SAC
policy_class:
  desc: null
  value: <class 'solutions.policies_sac.SACPolicyForPointFlowEnv'>
device:
  desc: null
  value: cuda:0
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{''pointnet_in_dim'': 4, ''pointnet_out_dim'': 32, ''pointnet_batchnorm'':
    False, ''pointnet_layernorm'': True, ''zero_init_output'': True, ''use_sde'':
    False}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 500000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: 0
action_noise:
  desc: null
  value: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5 0.5])), n_envs=12)
start_time:
  desc: null
  value: 1710683744015142482
learning_rate:
  desc: null
  value: 0.0001
tensorboard_log:
  desc: null
  value: /media/lab/data/yzk/ManiSkill-ViTac2024/scripts/../training_log/3shape_1.5mm_batch_size_512_lr_0.0001_2024-03-17_21-55-33.140
_last_obs:
  desc: null
  value: "OrderedDict([('gt_offset', array([[-4.5643377 ,  4.5755987 , -2.7638187\
    \ ],\n       [-2.9837856 , -4.503588  , -2.4481523 ],\n       [ 3.5494635 , -1.3385429\
    \ , -8.895663  ],\n       [ 1.5450317 ,  0.14200999, -2.3304396 ],\n       [-0.3781562\
    \ ,  0.8270013 ,  6.9806576 ],\n       [ 2.7316382 , -0.60528326, -8.574862  ],\n\
    \       [ 0.12221234,  1.777023  , -4.5123568 ],\n       [ 0.6373508 , -4.058494\
    \  , -8.986986  ],\n       [-1.9320883 , -2.5414467 ,  7.687347  ],\n       [\
    \ 2.7364788 ,  4.516683  ,  5.942588  ],\n       [-4.954273  ,  0.50699407, -2.9615023\
    \ ],\n       [-3.866252  ,  0.65141493,  4.2120876 ]], dtype=float32)), ('marker_flow',\
    \ array([[[[[ 21.737    ,  24.917324 ],\n          [ 56.40565  ,  21.586117 ],\n\
    \          [ 87.5974   ,  17.613306 ],\n          ...,\n          [304.6797  \
    \ , 217.64005  ],\n          [304.6797   , 217.64005  ],\n          [304.6797\
    \   , 217.64005  ]],\n\n         [[ 24.166037 ,  24.89336  ],\n          [ 57.974586\
    \ ,  20.477974 ],\n          [ 90.124725 ,  17.53525  ],\n          ...,\n   \
    \       [309.40997  , 217.8173   ],\n          [309.40997  , 217.8173   ],\n \
    \         [309.40997  , 217.8173   ]]],\n\n\n        [[[ 82.7577   ,  11.919215\
    \ ],\n          [114.72693  ,  11.933714 ],\n          [148.03574  ,  15.549927\
    \ ],\n          ...,\n          [ 93.78919  , 236.73485  ],\n          [ 93.78919\
    \  , 236.73485  ],\n          [ 93.78919  , 236.73485  ]],\n\n         [[ 84.892334\
    \ ,  12.577523 ],\n          [117.636284 ,  11.995927 ],\n          [151.4926\
    \   ,  14.449575 ],\n          ...,\n          [ 97.95281  , 236.99237  ],\n \
    \         [ 97.95281  , 236.99237  ],\n          [ 97.95281  , 236.99237  ]]]],\n\
    \n\n\n       [[[[ 40.572445 ,  20.397524 ],\n          [ 73.110954 ,  16.938951\
    \ ],\n          [106.252686 ,  16.184853 ],\n          ...,\n          [284.55017\
    \  , 234.87941  ],\n          [284.55017  , 234.87941  ],\n          [284.55017\
    \  , 234.87941  ]],\n\n         [[ 42.65004  ,  19.817184 ],\n          [ 75.41693\
    \  ,  16.225136 ],\n          [109.51705  ,  15.323168 ],\n          ...,\n  \
    \        [287.8514   , 235.52788  ],\n          [287.8514   , 235.52788  ],\n\
    \          [287.8514   , 235.52788  ]]],\n\n\n        [[[ 22.103964 ,  24.27114\
    \  ],\n          [ 53.810726 ,  19.270311 ],\n          [ 86.73784  ,  19.314983\
    \ ],\n          ...,\n          [296.38947  , 218.77672  ],\n          [296.38947\
    \  , 218.77672  ],\n          [296.38947  , 218.77672  ]],\n\n         [[ 24.261644\
    \ ,  23.294523 ],\n          [ 56.918915 ,  20.978746 ],\n          [ 89.08647\
    \  ,  18.046673 ],\n          ...,\n          [298.24124  , 219.43826  ],\n  \
    \        [298.24124  , 219.43826  ],\n          [298.24124  , 219.43826  ]]]],\n\
    \n\n\n       [[[[ 27.449022 ,  20.854797 ],\n          [ 61.1481   ,  16.934383\
    \ ],\n          [ 92.470894 ,  13.32032  ],\n          ...,\n          [302.29056\
    \  , 216.25784  ],\n          [302.29056  , 216.25784  ],\n          [302.29056\
    \  , 216.25784  ]],\n\n         [[ 30.651333 ,  19.643934 ],\n          [ 65.406715\
    \ ,  16.03553  ],\n          [ 96.1429   ,  14.661676 ],\n          ...,\n   \
    \       [305.4562   , 215.14317  ],\n          [305.4562   , 215.14317  ],\n \
    \         [305.4562   , 215.14317  ]]],\n\n\n        [[[ 29.690409 ,  32.174206\
    \ ],\n          [ 61.39181  ,  31.069103 ],\n          [ 91.49764  ,  34.75896\
    \  ],\n          ...,\n          [311.8661   , 225.32735  ],\n          [311.8661\
    \   , 225.32735  ],\n          [311.8661   , 225.32735  ]],\n\n         [[ 31.23481\
    \  ,  32.473133 ],\n          [ 63.556576 ,  31.75468  ],\n          [ 95.03734\
    \  ,  34.45009  ],\n          ...,\n          [315.71838  , 226.78835  ],\n  \
    \        [315.71838  , 226.78835  ],\n          [315.71838  , 226.78835  ]]]],\n\
    \n\n\n       ...,\n\n\n\n       [[[[  6.0777655,  13.42656  ],\n          [ 36.513744\
    \ ,  14.0121155],\n          [ 69.17137  ,  14.3531275],\n          ...,\n   \
    \       [313.4747   , 237.67503  ],\n          [313.4747   , 237.67503  ],\n \
    \         [313.4747   , 237.67503  ]],\n\n         [[  7.9869704,  13.71731  ],\n\
    \          [ 40.33254  ,  15.14615  ],\n          [ 72.3382   ,  15.095665 ],\n\
    \          ...,\n          [317.47937  , 237.42566  ],\n          [317.47937 \
    \ , 237.42566  ],\n          [317.47937  , 237.42566  ]]],\n\n\n        [[[ 84.09925\
    \  ,  11.950539 ],\n          [151.93785  ,  11.024704 ],\n          [185.05533\
    \  ,  12.661335 ],\n          ...,\n          [314.22546  , 237.94672  ],\n  \
    \        [314.22546  , 237.94672  ],\n          [314.22546  , 237.94672  ]],\n\
    \n         [[ 86.44857  ,  11.5475235],\n          [154.61165  ,  10.730476 ],\n\
    \          [188.03136  ,  11.852344 ],\n          ...,\n          [316.58865 \
    \ , 237.77876  ],\n          [316.58865  , 237.77876  ],\n          [316.58865\
    \  , 237.77876  ]]]],\n\n\n\n       [[[[ 25.03738  ,  24.043097 ],\n         \
    \ [ 57.66952  ,  22.412514 ],\n          [ 93.612236 ,  24.242453 ],\n       \
    \   ...,\n          [293.5322   , 211.67366  ],\n          [293.5322   , 211.67366\
    \  ],\n          [293.5322   , 211.67366  ]],\n\n         [[ 29.493692 ,  23.17183\
    \  ],\n          [ 62.18561  ,  22.068422 ],\n          [ 97.32431  ,  23.495676\
    \ ],\n          ...,\n          [297.9912   , 210.033    ],\n          [297.9912\
    \   , 210.033    ],\n          [297.9912   , 210.033    ]]],\n\n\n        [[[\
    \ 12.009545 ,  11.63686  ],\n          [ 14.441468 ,  41.01984  ],\n         \
    \ [ 47.07197  ,  41.635426 ],\n          ...,\n          [298.68896  , 213.68823\
    \  ],\n          [298.68896  , 213.68823  ],\n          [298.68896  , 213.68823\
    \  ]],\n\n         [[ 15.3040085,  12.505849 ],\n          [ 18.55151  ,  41.03649\
    \  ],\n          [ 50.454094 ,  42.293762 ],\n          ...,\n          [302.0757\
    \   , 214.08636  ],\n          [302.0757   , 214.08636  ],\n          [302.0757\
    \   , 214.08636  ]]]],\n\n\n\n       [[[[ 42.846607 ,  28.7394   ],\n        \
    \  [ 73.374535 ,  28.780529 ],\n          [110.87654  ,  27.728416 ],\n      \
    \    ...,\n          [284.59906  , 217.45633  ],\n          [284.59906  , 217.45633\
    \  ],\n          [284.59906  , 217.45633  ]],\n\n         [[ 45.981064 ,  28.934626\
    \ ],\n          [ 76.65142  ,  28.565168 ],\n          [113.18597  ,  27.59641\
    \  ],\n          ...,\n          [286.4466   , 217.82285  ],\n          [286.4466\
    \   , 217.82285  ],\n          [286.4466   , 217.82285  ]]],\n\n\n        [[[140.1568\
    \   ,  15.680634 ],\n          [169.36136  ,  17.89993  ],\n          [201.78589\
    \  ,  17.66993  ],\n          ...,\n          [284.76242  , 233.78593  ],\n  \
    \        [284.76242  , 233.78593  ],\n          [284.76242  , 233.78593  ]],\n\
    \n         [[142.06496  ,  16.123201 ],\n          [172.76384  ,  17.174246 ],\n\
    \          [204.75337  ,  17.801996 ],\n          ...,\n          [287.84848 \
    \ , 233.20813  ],\n          [287.84848  , 233.20813  ],\n          [287.84848\
    \  , 233.20813  ]]]]], dtype=float32))])"
_last_episode_starts:
  desc: null
  value: '[ True  True  True  True  True  True  True  True  True  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: 'Dict(''gt_offset'': Box(-3.4028235e+38, 3.4028235e+38, (3,), float32), ''marker_flow'':
    Box(-3.4028235e+38, 3.4028235e+38, (2, 2, 128, 2), float32))'
action_space:
  desc: null
  value: Box(-1.0, 1.0, (3,), float32)
n_envs:
  desc: null
  value: 12
buffer_size:
  desc: null
  value: 200000
batch_size:
  desc: null
  value: 512
learning_starts:
  desc: null
  value: 2000
tau:
  desc: null
  value: 0.005
gamma:
  desc: null
  value: 0.99
gradient_steps:
  desc: null
  value: -1
optimize_memory_usage:
  desc: null
  value: 'False'
replay_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.DictReplayBuffer object at 0x7fcd6cc98940>
replay_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.DictReplayBuffer'>
replay_buffer_kwargs:
  desc: null
  value: '{}'
_episode_storage:
  desc: null
  value: None
train_freq:
  desc: null
  value: 'TrainFreq(frequency=2, unit=<TrainFrequencyUnit.STEP: ''step''>)'
use_sde_at_warmup:
  desc: null
  value: 'False'
target_entropy:
  desc: null
  value: -3.0
log_ent_coef:
  desc: null
  value: tensor([0.], device='cuda:0', requires_grad=True)
ent_coef:
  desc: null
  value: auto
target_update_interval:
  desc: null
  value: 1
ent_coef_optimizer:
  desc: null
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay:\
    \ 0\n)"
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x7fcd94bcdcf0>
actor:
  desc: null
  value: "Actor(\n  (features_extractor): FeatureExtractorWithPointNetEncoder(\n \
    \   (feature_extractor_net): PointNetFeatureExtractor(\n      (pointnet_local_fea):\
    \ Sequential(\n        (0): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n   \
    \     (1): Identity()\n        (2): ReLU()\n        (3): Conv1d(64, 64, kernel_size=(1,),\
    \ stride=(1,))\n        (4): Identity()\n        (5): ReLU()\n      )\n      (pointnet_global_fea):\
    \ PointNetFeaNew(\n        (conv0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n\
    \        (bn0): Identity()\n        (conv1): Conv1d(64, 128, kernel_size=(1,),\
    \ stride=(1,))\n        (bn1): Identity()\n        (conv2): Conv1d(128, 512, kernel_size=(1,),\
    \ stride=(1,))\n        (bn2): Identity()\n      )\n      (mlp_output): Sequential(\n\
    \        (0): Linear(in_features=512, out_features=256, bias=True)\n        (1):\
    \ ReLU()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \        (3): ReLU()\n        (4): Linear(in_features=256, out_features=32, bias=True)\n\
    \      )\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=64,\
    \ out_features=256, bias=True)\n    (1): Identity()\n    (2): ReLU()\n    (3):\
    \ Linear(in_features=256, out_features=256, bias=True)\n    (4): Identity()\n\
    \    (5): ReLU()\n    (6): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (7): Tanh()\n  )\n  (mu): Linear(in_features=256, out_features=3, bias=True)\n\
    \  (log_std): Linear(in_features=256, out_features=3, bias=True)\n)"
critic:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
critic_target:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
batch_norm_stats:
  desc: null
  value: '[]'
batch_norm_stats_target:
  desc: null
  value: '[]'
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7fcd6cd7d000>
