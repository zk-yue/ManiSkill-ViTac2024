wandb_version: 1

env:
  desc: null
  value:
    step_penalty: 1
    final_reward: 10
    max_action:
    - 2.0
    - 2.0
    - 4.0
    max_steps: 8
    z_step_size: 0.125
    peg_hole_path_file: configs/peg_insertion/3shape_1.5mm.txt
    peg_x_max_offset: 5.0
    peg_y_max_offset: 5.0
    peg_theta_max_offset: 10.0
    marker_interval_range:
    - 1.95
    - 2.15
    marker_rotation_range: 0.1
    marker_translation_range:
    - 1
    - 1
    marker_pos_shift_range:
    - 0.1
    - 0.1
    marker_random_noise: 0.5
    marker_lose_tracking_probability: 0.01
    normalize: false
policy:
  desc: null
  value:
    buffer_size: 200000
    train_freq: 2
    gradient_steps: -1
    learning_starts: 2000
    action_noise: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5
      0.5])), n_envs=12)
    batch_size: 512
    learning_rate: 0.0001
    optimize_memory_usage: false
    ent_coef: auto
    target_update_interval: 1
    target_entropy: auto
    use_sde: false
    sde_sample_freq: -1
    use_sde_at_warmup: false
    policy_kwargs:
      pointnet_in_dim: 4
      pointnet_out_dim: 32
      pointnet_batchnorm: false
      pointnet_layernorm: true
      zero_init_output: true
      use_sde: false
    device: cuda:0
    seed: 0
    tensorboard_log: /home/lab404/YZK/ManiSkill_Vitac/ManiSkill-ViTac2024/scripts/../training_log/3shape_1.5mm_batch_size_512_lr_0.0001_2024-03-20_11-58-56.092
train:
  desc: null
  value:
    total_timesteps: 500000
    log_interval: 6
    checkpoint_every: 2000
    eval_freq: 2000
    n_eval: 50
    parallel: 12
    seed: 0
    device: cuda:0
    gpu: 0
    name: 3shape_1.5mm_batch_size_512_lr_0.0001
    wandb_name: ManiSkill_ViTac
    emp: {}
cfg:
  desc: null
  value: configs/parameters/peg_insertion_sac.yaml
no_render:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    code_path: code/scripts/train_sac.py
    python_version: 3.10.0
    cli_version: 0.16.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1710907145.986663
    t:
      1:
      - 1
      - 5
      - 53
      - 55
      2:
      - 1
      - 5
      - 53
      - 55
      3:
      - 13
      - 16
      - 22
      - 23
      - 35
      4: 3.10.0
      5: 0.16.0
      8:
      - 5
      13: linux-x86_64
algo:
  desc: null
  value: SAC
policy_class:
  desc: null
  value: <class 'solutions.policies_sac.SACPolicyForPointFlowEnv'>
device:
  desc: null
  value: cuda:0
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{''pointnet_in_dim'': 4, ''pointnet_out_dim'': 32, ''pointnet_batchnorm'':
    False, ''pointnet_layernorm'': True, ''zero_init_output'': True, ''use_sde'':
    False}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 500000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: 0
action_noise:
  desc: null
  value: VecNoise(BaseNoise=NormalActionNoise(mu=[0 0 0], sigma=[0.5 0.5 0.5])), n_envs=12)
start_time:
  desc: null
  value: 1710907175618875966
learning_rate:
  desc: null
  value: 0.0001
tensorboard_log:
  desc: null
  value: /home/lab404/YZK/ManiSkill_Vitac/ManiSkill-ViTac2024/scripts/../training_log/3shape_1.5mm_batch_size_512_lr_0.0001_2024-03-20_11-58-56.092
_last_obs:
  desc: null
  value: "OrderedDict([('gt_offset', array([[ 4.980397  , -0.8651874 , -9.025712 \
    \ ],\n       [-0.60227793, -3.6679623 , -7.2449346 ],\n       [ 0.07741086, -2.3177032\
    \ , -2.7123797 ],\n       [-1.2369121 , -4.6161127 , -6.636562  ],\n       [-1.4813951\
    \ , -4.2752876 , -0.2512303 ],\n       [ 2.9354246 ,  2.5129151 , -6.7501183 ],\n\
    \       [ 4.897005  , -0.73884034,  3.6400385 ],\n       [-1.3032235 ,  0.79394364,\
    \ -2.927879  ],\n       [-3.816294  ,  2.0170178 ,  2.172491  ],\n       [-3.4343402\
    \ , -4.154404  ,  8.773714  ],\n       [ 4.9958897 ,  0.1675003 ,  3.9597826 ],\n\
    \       [ 3.311755  ,  1.7054812 ,  3.0516586 ]], dtype=float32)), ('marker_flow',\
    \ array([[[[[ 19.506763 ,  37.666134 ],\n          [ 54.48073  ,  36.350784 ],\n\
    \          [ 86.32533  ,  32.093    ],\n          ...,\n          [305.59662 \
    \ , 208.41888  ],\n          [305.59662  , 208.41888  ],\n          [305.59662\
    \  , 208.41888  ]],\n\n         [[ 21.667318 ,  38.11635  ],\n          [ 58.288227\
    \ ,  36.28225  ],\n          [ 90.78058  ,  30.536345 ],\n          ...,\n   \
    \       [308.84012  , 209.767    ],\n          [308.84012  , 209.767    ],\n \
    \         [308.84012  , 209.767    ]]],\n\n\n        [[[231.00558  ,  13.685875\
    \ ],\n          [262.7274   ,  16.300543 ],\n          [295.92322  ,  18.432127\
    \ ],\n          ...,\n          [275.3327   , 238.15056  ],\n          [275.3327\
    \   , 238.15056  ],\n          [275.3327   , 238.15056  ]],\n\n         [[234.28592\
    \  ,  13.79941  ],\n          [266.2888   ,  16.13082  ],\n          [299.19168\
    \  ,  16.999592 ],\n          ...,\n          [279.09814  , 239.48325  ],\n  \
    \        [279.09814  , 239.48325  ],\n          [279.09814  , 239.48325  ]]]],\n\
    \n\n\n       [[[[ 28.715307 ,  31.05128  ],\n          [ 63.109364 ,  26.2194\
    \   ],\n          [ 95.834816 ,  24.654469 ],\n          ...,\n          [315.49207\
    \  , 204.11826  ],\n          [315.49207  , 204.11826  ],\n          [315.49207\
    \  , 204.11826  ]],\n\n         [[ 31.096718 ,  30.378395 ],\n          [ 64.445274\
    \ ,  26.976982 ],\n          [ 99.03118  ,  24.788614 ],\n          ...,\n   \
    \       [318.80704  , 202.60648  ],\n          [318.80704  , 202.60648  ],\n \
    \         [318.80704  , 202.60648  ]]],\n\n\n        [[[  6.313975 ,  20.157753\
    \ ],\n          [ 38.767754 ,  24.62602  ],\n          [ 71.20983  ,  26.486872\
    \ ],\n          ...,\n          [291.59384  , 229.51637  ],\n          [291.59384\
    \  , 229.51637  ],\n          [291.59384  , 229.51637  ]],\n\n         [[  8.444759\
    \ ,  20.796534 ],\n          [ 40.8943   ,  24.771727 ],\n          [ 75.32515\
    \  ,  26.260168 ],\n          ...,\n          [295.31372  , 229.93721  ],\n  \
    \        [295.31372  , 229.93721  ],\n          [295.31372  , 229.93721  ]]]],\n\
    \n\n\n       [[[[ 28.799158 ,  29.332542 ],\n          [ 64.46379  ,  31.807594\
    \ ],\n          [ 96.67468  ,  32.310684 ],\n          ...,\n          [288.57614\
    \  , 225.04675  ],\n          [288.57614  , 225.04675  ],\n          [288.57614\
    \  , 225.04675  ]],\n\n         [[ 32.010998 ,  29.460379 ],\n          [ 67.0833\
    \   ,  31.196844 ],\n          [ 98.13104  ,  32.542732 ],\n          ...,\n \
    \         [290.50327  , 224.48741  ],\n          [290.50327  , 224.48741  ],\n\
    \          [290.50327  , 224.48741  ]]],\n\n\n        [[[ 49.35179  ,  38.851852\
    \ ],\n          [ 84.33662  ,  38.486042 ],\n          [115.5407   ,  39.46531\
    \  ],\n          ...,\n          [246.06555  , 235.65962  ],\n          [246.06555\
    \  , 235.65962  ],\n          [246.06555  , 235.65962  ]],\n\n         [[ 51.997997\
    \ ,  39.94653  ],\n          [ 86.895996 ,  38.826885 ],\n          [118.013565\
    \ ,  39.842712 ],\n          ...,\n          [249.29807  , 235.529    ],\n   \
    \       [249.29807  , 235.529    ],\n          [249.29807  , 235.529    ]]]],\n\
    \n\n\n       ...,\n\n\n\n       [[[[  9.279774 ,  15.381885 ],\n          [ 41.524666\
    \ ,  16.23212  ],\n          [ 77.18667  ,  20.43407  ],\n          ...,\n   \
    \       [ 59.766953 , 238.3187   ],\n          [ 59.766953 , 238.3187   ],\n \
    \         [ 59.766953 , 238.3187   ]],\n\n         [[ 12.501094 ,  15.518932 ],\n\
    \          [ 45.970776 ,  15.484877 ],\n          [ 79.459274 ,  21.319368 ],\n\
    \          ...,\n          [ 62.563484 , 239.01137  ],\n          [ 62.563484\
    \ , 239.01137  ],\n          [ 62.563484 , 239.01137  ]]],\n\n\n        [[[153.40562\
    \  ,  10.470403 ],\n          [223.27745  ,  13.0223675],\n          [255.7641\
    \   ,  12.451381 ],\n          ...,\n          [ 42.184677 , 237.34866  ],\n \
    \         [ 42.184677 , 237.34866  ],\n          [ 42.184677 , 237.34866  ]],\n\
    \n         [[157.37296  ,  11.240086 ],\n          [225.15866  ,  11.530783 ],\n\
    \          [259.39014  ,  12.935273 ],\n          ...,\n          [ 45.85279 \
    \ , 237.97873  ],\n          [ 45.85279  , 237.97873  ],\n          [ 45.85279\
    \  , 237.97873  ]]]],\n\n\n\n       [[[[ 37.33611  ,  31.78991  ],\n         \
    \ [ 70.862854 ,  29.616219 ],\n          [102.892075 ,  27.951231 ],\n       \
    \   ...,\n          [287.95538  , 207.02571  ],\n          [287.95538  , 207.02571\
    \  ],\n          [287.95538  , 207.02571  ]],\n\n         [[ 39.890274 ,  31.703335\
    \ ],\n          [ 72.58911  ,  29.570948 ],\n          [105.68404  ,  28.54974\
    \  ],\n          ...,\n          [291.2431   , 207.61194  ],\n          [291.2431\
    \   , 207.61194  ],\n          [291.2431   , 207.61194  ]]],\n\n\n        [[[\
    \ 29.621752 ,  20.28664  ],\n          [ 61.065193 ,  23.38096  ],\n         \
    \ [ 91.68167  ,  26.716715 ],\n          ...,\n          [ 72.733665 , 237.4911\
    \   ],\n          [ 72.733665 , 237.4911   ],\n          [ 72.733665 , 237.4911\
    \   ]],\n\n         [[ 32.016293 ,  20.394762 ],\n          [ 62.850838 ,  23.646118\
    \ ],\n          [ 93.6608   ,  27.11697  ],\n          ...,\n          [ 75.51511\
    \  , 238.01944  ],\n          [ 75.51511  , 238.01944  ],\n          [ 75.51511\
    \  , 238.01944  ]]]],\n\n\n\n       [[[[ 18.025583 ,  37.668278 ],\n         \
    \ [ 52.13204  ,  38.056683 ],\n          [ 85.265396 ,  32.917038 ],\n       \
    \   ...,\n          [304.3633   , 209.6346   ],\n          [304.3633   , 209.6346\
    \   ],\n          [304.3633   , 209.6346   ]],\n\n         [[ 21.637486 ,  37.772102\
    \ ],\n          [ 55.574867 ,  37.341213 ],\n          [ 87.560684 ,  32.789917\
    \ ],\n          ...,\n          [307.86618  , 211.21715  ],\n          [307.86618\
    \  , 211.21715  ],\n          [307.86618  , 211.21715  ]]],\n\n\n        [[[285.44785\
    \  ,  12.694032 ],\n          [  9.016658 ,  28.889036 ],\n          [ 44.43111\
    \  ,  32.73158  ],\n          ...,\n          [233.43855  , 237.72598  ],\n  \
    \        [233.43855  , 237.72598  ],\n          [233.43855  , 237.72598  ]],\n\
    \n         [[287.51486  ,  13.071609 ],\n          [ 12.373676 ,  29.283937 ],\n\
    \          [ 45.9011   ,  33.44709  ],\n          ...,\n          [237.78468 \
    \ , 238.05898  ],\n          [237.78468  , 238.05898  ],\n          [237.78468\
    \  , 238.05898  ]]]]], dtype=float32))])"
_last_episode_starts:
  desc: null
  value: '[ True  True  True  True  True  True  True  True  True  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: 'Dict(''gt_offset'': Box(-3.4028235e+38, 3.4028235e+38, (3,), float32), ''marker_flow'':
    Box(-3.4028235e+38, 3.4028235e+38, (2, 2, 128, 2), float32))'
action_space:
  desc: null
  value: Box(-1.0, 1.0, (3,), float32)
n_envs:
  desc: null
  value: 12
buffer_size:
  desc: null
  value: 200000
batch_size:
  desc: null
  value: 512
learning_starts:
  desc: null
  value: 2000
tau:
  desc: null
  value: 0.005
gamma:
  desc: null
  value: 0.99
gradient_steps:
  desc: null
  value: -1
optimize_memory_usage:
  desc: null
  value: 'False'
replay_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.DictReplayBuffer object at 0x7fbbd031bd60>
replay_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.DictReplayBuffer'>
replay_buffer_kwargs:
  desc: null
  value: '{}'
_episode_storage:
  desc: null
  value: None
train_freq:
  desc: null
  value: 'TrainFreq(frequency=2, unit=<TrainFrequencyUnit.STEP: ''step''>)'
use_sde_at_warmup:
  desc: null
  value: 'False'
target_entropy:
  desc: null
  value: -3.0
log_ent_coef:
  desc: null
  value: tensor([0.], device='cuda:0', requires_grad=True)
ent_coef:
  desc: null
  value: auto
target_update_interval:
  desc: null
  value: 1
ent_coef_optimizer:
  desc: null
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay:\
    \ 0\n)"
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x7fbbd032e3b0>
actor:
  desc: null
  value: "Actor(\n  (features_extractor): FeatureExtractorWithPointNetEncoder(\n \
    \   (feature_extractor_net): PointNetFeatureExtractor(\n      (pointnet_local_fea):\
    \ Sequential(\n        (0): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n   \
    \     (1): Identity()\n        (2): ReLU()\n        (3): Conv1d(64, 64, kernel_size=(1,),\
    \ stride=(1,))\n        (4): Identity()\n        (5): ReLU()\n      )\n      (pointnet_global_fea):\
    \ PointNetFeaNew(\n        (conv0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n\
    \        (bn0): Identity()\n        (conv1): Conv1d(64, 128, kernel_size=(1,),\
    \ stride=(1,))\n        (bn1): Identity()\n        (conv2): Conv1d(128, 512, kernel_size=(1,),\
    \ stride=(1,))\n        (bn2): Identity()\n      )\n      (mlp_output): Sequential(\n\
    \        (0): Linear(in_features=512, out_features=256, bias=True)\n        (1):\
    \ ReLU()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \        (3): ReLU()\n        (4): Linear(in_features=256, out_features=32, bias=True)\n\
    \      )\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=64,\
    \ out_features=256, bias=True)\n    (1): Identity()\n    (2): ReLU()\n    (3):\
    \ Linear(in_features=256, out_features=256, bias=True)\n    (4): Identity()\n\
    \    (5): ReLU()\n    (6): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (7): Tanh()\n  )\n  (mu): Linear(in_features=256, out_features=3, bias=True)\n\
    \  (log_std): Linear(in_features=256, out_features=3, bias=True)\n)"
critic:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
critic_target:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CriticFeatureExtractor()\n  (qf0):\
    \ Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n \
    \   (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n  (qf1): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n\
    \    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n\
    \    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n\
    \  )\n)"
batch_norm_stats:
  desc: null
  value: '[]'
batch_norm_stats_target:
  desc: null
  value: '[]'
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7fbcdcb57430>
